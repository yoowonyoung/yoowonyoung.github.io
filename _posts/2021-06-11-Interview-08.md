---
layout: post
title: "쿠팡면접 및 스노우 준비"
description: 쿠팡면접 및 스노우 준비
date: 2021-06-11 13:44:00 +09:00
categories: Interview
---

# 자기소개
안녕하세요 현재 카카오 비즈개발실 채널서비스개발 파트에 재직중인 유원영입니다.

저는 이전 직장인 삼성리서치에서는 약 3년동안 재직 하였는데, 재직기간 동안 In-house 서비스인 개발 데이터 가시화 Dashboard의 Backend 서버를 개발 했었습니다. 
해당 서비스는 개발 과정에서 모이는 git log, jira issue, static analysis 결과 등 여러 데이터를 모아, 이를 가시화 해서 보여주는 서비스로, 개발 초기 당시에는 삼성리서치 사업부 대상으로만 제공되었지만 
나중엔 해외연구소를 포함한 삼성전자 전체 사업부를 대상으로 서비스를 했었습니다.

이후 카카오로 이직하여, 멜론 개발실에서 멜론 콘텐츠 개발 프로젝트에 백엔드 개발자로 참여, 멜론의 트랙제로기능에 대한 추천 트랙 리스트 관리 기능을 제작하며, 
기획자가 해당 기능을 사용하기 위한 내부 어드민 페이지도 같이 제작 하였고, 멜론의 레거시 백엔드 코드 개선작업에도 참여, 16년된 멜론의 가사 등록 모듈을 개선하기도 하였습니다. 
현재는 채널서비스 개발파트로 옮겨, 카카오for비즈니스 서비스의 기존 CI/CD 환경을 Kubernetes 환경에 맞게 고도화 하는 업무와 카카오페이 구매 간편설정 관련 기능을 개발 하고있습니다.

저는 계속 Spring/Java 기반의 Backend개발을 하였고 인프라를 직접 다뤘기 때문에 Spring framerowk에 대한 전반적인 이해 뿐만 아니라, 
Mysql/PostgreSQL/Oracle 등 다양한 DB에 대한 사용 경험 및, 
서비스를 Dockerize하여 CircleCI 및 Artifatcory 와 연동하여 PR생성시 자동 Test 및 Docker image까지 백업 하며 Ansible을 통해서 프로비저닝하는 환경을 직접 구축한 경험도 있습니다. 
이러한 배경 지식과 경험을 바탕으로 더욱더 발전하면서 기여하고싶습니다. 

# 카카오에서의 경력이 짧은데 왜 이직 하게 되었는가
카카오의 문화와 맞지 않다고 생각해서. 카카오 엔터테인먼트 분사와 관련해서 이슈가 있었음. 카카오 엔터테인먼트가 출범하면서 내가 속해있던 멜론도 카카오 엔터테인먼트로 합병이 될 예정이였음. 입사후 수습기간도 풀리지않았는데 전달받은 소식이긴 했지만 그래도 긍정적으로 생각하고 있었음. 이동에 대한 거부감도 크게 없었고, 사업적 측면에서 봣을땐 당연할뿐만아니라 컨텐츠 산업끼리 시너지를 낼 수 있는 환경이 만들어지는것이라 개발자로써 여러 새로운 경험을 해볼수 있을것이라 생각하였음. 하지만 전적동의를 구하는 과정에서, 전적 이후 카카오 엔터테인먼트에서의 개발 환경이나 인프라 심지어 복지나 처우까지 정해진것이 하나 없는 상황에서 짧은 기간 동안 전적 동의를 구하였고 이에 수많은 동료들이 항의 하였지만 회사는 강행하였음. 그래서 이대로는 결정을 내릴수 없었기에 선택을 보류했는데, 선택을 보류한 인력은 본사에 잔류시킨다는 카카오의 결정에 따라, 카카오 본사에 잔류하게 되었음. 잔류 이후 재배치 프로세스에서도 좀 문제가 잇었는데, 첫 설명회 당시에는 잔류 이후 재배치 프로세스에 대해서 개인이 원하는 부서를 최대한 반영해준다고 말하였으나, 실제 재배치 프로세스에서는 개인의 의사가 아닌 회사 결정에 따라 전략배치가 이뤄졌었음. 그래서 배치받을 조직의 조직장분과 면담 한번 해보지 못한채 인사 이동 공고를 통해 배치 부서를 확인 하게 되었음. 그러한 과정을 거치면서 상당한 스트레스를 받게 되었고, 카카오의 문화와 나는 맞지 않다고 판단, 그로인해 이직을 결심하게 되었음

# 스노우 주요 질문 정리
- 창업 기회 있으면 할것인가
    * 기회는 언제나 열려 있다고 생각한다. 주변에 창업을 한 사람들이 있는데, 그 사람들을 지켜보면 일이 좀 힘들더라도 자기가 하고 싶은일을, 자기가 주체가 되어서 하고 있어서 그런지 즐겁게 일하는 모습을 보았다. 나 또한 그런 기회가 된다면 그렇게 일해보고 싶다

- 장점
    * 일 할때는 항상 열정적으로, 에너지 넘치게 일을 하는 스타일이다. 이러한 내 에너지를 항상 팀원들과 함께하면서 함께 같은 목표를 향해 더 빠르게 달릴 수 있도록 노력한다
    * 모든 지식을 항상 팀원들과 함께 나누려고 한다. 혼자 스터디 한 내용이라도 내부 위키같은것을 통해서 공유하여서 팀원 모두에게 나누도 또 팀원들에게 공유받아서 다같이 성장을 도모한다
    * 다른 팀원이 어떤 문제에 처해 있다면 그 문제는 그 팀원만의 문제가 아니라 우리 팀 전체의 문제라고 생각한다. 같이 문제를 해결하려는 그 과정에서 배울것이 많다고 생각하기 때문에, 그런 문제는 항상 같이, 조금이나마 도움이 되도록 노력한다

- SNS 자주 하는지?
    * 평소에 요리하는것과 사진찍는것을 좋아해서 많은 사진을 자주 찍어서 인스타에 올리곤 한다
    * 또 사진 잘찍는 사람들을 팔로우해서 이러한 사람들로부터 영감을 받도록 한다

- wit앱 개선점
    * 설정의 문의 부분이 메일을 활용하도록 강제 하고 있다. 사실 이 부분은 문의 게시판을 운영하는게 더 좋지 않을까 한다
    * 요즘 많은 앱들이 다크모드를 지원하고 있는데 다크모드도 추가되면 좋지 않을까

- 갈등이 생겼을때 대처법
    * 최대한 갈등이 생긴 사람과 많은 대화를 해보려고 한다. 그 사람이 왜 그렇게 행동했을까에 대해서 생각도 해보고 그 사람의 입장이 되어보려고도 한다. 개인적인 감정은 최대한 배제 하도록 하지만, 불합리하다고 생각하는것에 대해서는 내 의견을 정확하게 전달하도록 노력한다

- 질문
    * 스노우는 상당히 여러 분야에 도전하고 있다. 이러한 아이디어는 어떻게 생각해내는건지 궁금하다.

- 하고싶은말
    * 이전에 있었던 1차면접에서 만낫던 면접관 분들이 되게 인상깊게 남았다. 면접과정에서 면접관분들의 활기찬 에너지를 느낄수 있었다. 그런 에너지 넘치는분들과 같이 일한다면, 나 또한 더더욱 에너지 넘치게 일하면서 일할수있을것이란 생각이 들었다. 이런분들과 함께 일하고싶다.

- 문제가 생겼을땐 어떻게 해결하는지
    * 먼저 문제가 생긴 원인을 파악하려 노력한다. 그래서 정확한 원인이 확인되면 이러한 문제 상황과 원인을 항상 공유한다. 내가 겪고있는 이 문제는 다른 팀원들이 먼저 겪어본것일수도 있으므로, 항상 공유 해서 도움을받을 받을수 있다면 받아서 해결하고, 문제가 해결된 이후엔 그 전체 트러블 슈팅 과정을 기록해서 다른 사람이 비슷한 과정을 겪는다면 좀 더 쉽게 해결 할 수 있도록 한다

# Dive Deep
Kakao for Business 의 API 서버를 Jenkins + Kubernetes 환경에 맞게 배포 프로세스를 변경하는 과정에서 겪었던 일. 
카카오의 개발 Phase는 Dev -> Sandbox -> CBT -> Prod의 순서였는데, 전임자가 이미 Dev Phase에 대한 작업을 완료해둔 상태였음. 그래서 그분이 만들어준 Jenkins Job을 바탕으로 이를 Sandbox Phase로도 확장하면서 
몇가지 요구사항만 더 적용하면 됫었었음. 그래서 처음에는 금방 끝낼 수 있을것이라 생각 하였지만, 하면서 몇가지 문제를 겪게 되었음. 
그래서 요구사항들을 모두 dev phase에 먼저 반영하고 그걸 바탕으로 sandbox를 구성했음. 그리고 sandbox를 실행 해보니 sandbox phase에서 사용하는 리소스가 더 많아서 그런지 실행은 정상적으로 되서 올라가고 있었지만, liveness probe check fail때문에 계속 restart가 발생했음.
그래서 그것도 startup probe를 이용해서 해결 하려고 했지만, kubernetes 버전이 1.14여서 startup probe를 지원하지 않았고, 이 문제를 해결하기 위한 방안으로 liveness probe의 initialDelaySecond를 조작해서 해결
작업을 계속해서 sandbox phase까지 확장 해서 정상작동하는것을 확인하고 이 변경사항을 dev phase에도 적용 했는데 원래 잘 되던 dev phase의 container가 계속 application 실행에 실패하는것이 보였음
원인을 확인 해보니 vault 설정파일을 읽지 못해서 계속 실패하고있었는데, 그 vault 설정을 읽지 못하는 원인을 찾아보려고 게속 노력했음. 하지만 해당 설정을 읽는 부분에 변화가 없었고, 또 sandbox 페이즈에 적용시킨거는 잘 됫었고, 또 내 local에서도 잘 됫어서 원인을 찾기 힘들었음 
도저히 못찾겟어서 같이 일하는 리더분한테도 도움을 요청했고 둘이 같이 확인해보다보니, 그분 local에서도 처음에는 똑간은 원인으로 안되다가, docker image를 새로 pull하면 잘 된다는걸 확인해서 kubernetes의 image pull policy가 문제였다고 추측
이걸 aluways로 수정 햇었음. 그런데 image pull policy에 대해서 깊게 확인을 해보면서 always여도 로컬에 있는 docker image의 이름 + 태그 + digest가 서버에 있는것과 동일 하다면 다운로드 시도는 하나 갱신이 되지 않는다는 사실도 알게됬음. 
그래서 지금 당장은 image pull policy를 always로 바꿔서 문제는 해결 되었지만, 또다른 문제가 발생할 가능성도 있어서 이것을 미연에 방지 하고 싶었음. 그래서 기존에는 build job에서 docker image 빌드시 매번 tag를 latest로 붙였는데, 이렇게 tag를 붙이지 말고 build number를 tag로 사용해서 버저닝을 해버렸음.
(찾아보니까 쿠버네티스 공식 가이드문서에서도 버전 추적의 문제 및 롤백시 어려움이 있어 실제 프로덕션 배포시에는 latest태그를 사용하는것을 지양하라고 되어있었음),
또한, deploy 잡에서 이 build number를 쓸 수 있도록 이 두개 job을 하나로 묶는 job을 또 만들어서 그 job에서 환경변수를 이용해서 전달하게 하면서 문제를 일단 해결 하였음. 또 이부분에 대해서도 우회적인 해결법이 아니라, 정석적으로 해결할 방법이 없을까 찾아보니, Jenkins의 몇몇 내장 Method에 대해서 권한을 주면, 다른 Job의 마지막으로 성공한 build number를 가져올수있다는것을 알게 되었고, deploy job에서 이를 사용해서 문제를 해결 하였음.
이러한 과정을 거치며 helm 에 대한 사용법, kubernetes 에 대한 지식, jenkins pipeline 구축에 대한 지식과 경험을 더 쌓을수 있었음

# Think Systematically
개발 Data 가시화 Dashboard를 진행하던 도중에 일. 기존 서비스는 아주 고전적인 방식으로 Jenkins를 통해 서버에서 서비스를 실행하는 방식으로 진행 되었었음. 
그러던중 새로운 서버를 얻게 되어 새 서버로 서비스를 이전하던 도중 발생한 일. 새 서버 셋업을 새로 들어오신분한테 맡겼었었고, 
이후 이전 당일이 되어서 프록시 변경 이후 새 서비스를 실행했는데, Jenkins에서 build fail이 발생했음. 금요일 저녁 늦은시간이여서 다행이 접속자는 없었지만, 그래도 서비스가 중단되었던것이기 때문에 빠른 재시작이 필요했음.
이전에 개발서버에서 확인할때는 문제가 없었던것에 착안해서, 개발서버와 운영서버 사이의 환경에 어딘가 차이가 있을것이라 판단해서 환경이 어떤것이 다른지 먼저 파악했음. 
그래서 jenkins잡에서 사용하는 maven버전이 달랏다는걸알게되고 maven버전을 변경해서 다시 실행시키고 서비스는 이내 정상화되었음.
이때를 교훈삼아 환경에 영향을 받지 않는 배포 방식이 필요하단 생각을 하였음. 그래서 service를 dockerize 한다음, docker image 빌드 자체도 circleci를 이용해서 하게 함으로써,
빌드 환경에 항상 같도록 만들었고, 실행 환경도 항상 같게 만들었음. 그 과정에서 circleci에서 매 빌드시마다 maven dependency를 받게되서 오래 걸리는 문제가 발생 했지만, 
다행이 사내 maven cache가 존재해서 이 문제를 해결했음. 그리고 항상 같이 실행되어야 하는것들(db)등도 싹 다 dockerize 한다음에 이걸 docker compose로 구성하고, 
이를 ansible을 통해 프로비저닝 하는 환경을 구축해서 다시는 이런 문제가 발생하지 않도록 했음

# Disagree and commit
삼성전자에서 일하던 시절에는 매 PR 생성시마다 reviewer로 부터 approve를 2개 이상 받아야지만 merge가 가능한 구조였어서 코드리뷰가 상당히 활성화 되어있었는데, 
그 과정에서 이와 관련된 경험이 많았음. 언제 한번은 Refactoring PR을 올렸던적이 있는데, 얼마 전부터 같이 일하는 시니어로부터 코멘트가 상당히 많이 달렷었었음. 
그중에는 뭐 else 보다는 early return을 사용해서 좀 더 명확하게 끝난것임을 알리자 부터 다양한 의견이 많이 나왓었음.
그중 수용할것도 많았기에 겸허히 받아들였지만, extract class 한 부분에 대해서는 추후 확장성을 고려하면 이렇게 클래스 추출이 맞다고 생각했음. 
그 부분이 지표 데이터를 만드는 부분이였는데, 이걸 지표별로 extract 한 이유가 사업부별로 다른 지표를 보여주기는 하지만 그 지표의 로직은 사업부별로 다르지 않기에 지표별로 추출하는게 맞아보였음.
그래야만이 추후 지표 산출 로직의 변경이나 지표 추가시 좀 더 쉽게 대처가 가능할것이라고 생각했기 때문
그래서 이에 관한 내 의견을 말하고, 페어프로그래밍으로 직접 같이 리팩토링을 진행하기도 하면서 내가 가지고 있는 컨셉 공유하려 노력했고, 결국 그분도 그 컨셉을 이해해서 PR은 merge되게 되었음. 이때를 기점으로 그분과는 자주 pair로 같이 작업을 진행하며 서로 가지고 있는 컨셉을 공유하기도 하고 많이 배우기도 했었었음

# Java

1.  자바의 JVM의 역할에 대해서 설명해 보시오(메모리 종류 포함)
    - Java Virtual Machine, JAVA와 OS 사이에서 중계자 역할, JAVA가 OS에 구애받지 않고 재사용을 가능하게 해 줌
    - Class Loader: 컴파일 된 class 파일들을 Runtime Data Area에 적재
    - Execution Engine: Class Loader에 의해 적재된 클래스들을 기계어로 변경해 명령어 단위로 실행 (명령어를 하나하나 실행하는 인터프리터 방식과, JIT - 적절한 시간에 전체 바이트 코드를 네이티브 코드로 변경해서 Execution Engine이 네이티브로 컴파일된 코드를 실행해서 성능을 높이는 방식이 있음)
    - Garbage Collector: 힙 메모리 영역에 생성된 객체들중 참조되지 않는 객체를 찾아서 제거. GC중엔 다른 모든 스레드가 일시정지
    - 메모리 영역은 Runtime Data Area 속의 클래스, 힙, 스택, Native 메서드, PC레지스터로 구성
        * 클래스 영역: Method영역, Code 영역, Static영역 등으로 불림
            + Field Information: 멤버변수의 이름, 데이터 타입, 접근제어자에 대한 정보
            + Method Information: 메서드의 이름, 리턴타입, 매개변수, 접근제어자에 대한 정보
            + Type Information: 타입의 속성이 Class인지 Interface인지 여부 저장, Type의 전체 이름(패키지먕 + 클래스명), Type의 Super class의 전체이름, 접근제어자 및 연관된 interface의 정보
            + 상수풀: Type에서 사용된 상수들이 저장. 문자상수, 타입, 필드, Metho의 symbolic reference도 상수에 저장
            + class variable: static 변수, 모든 객체가 공유, 객체 생성 없이 접근 가능
            + Class 사용 이전에 메모리 할당: final class변수의 경우 상수로 치환되어 상수풀에 저장
        
        * 스택: 메서드 호출시마다 각각의 스택 프레임(메서드만을 위한 공간)이 생성, 메서드 안에서 사용되어지는 값들을 저장, 호출된 메서드의 메개변수, 지역변수, 리턴값, 연산시 일어나는 값들을 임시 저장
        * 힙: new 연산자로 생성된 객체와 배열을 저장하는 공간, 클래스 영역에 로드된 클래스만 생성가능, GC에 의해 관리되는 영역
            + Permanent Generation: 생성된 객체들의 주소값이 저장되는 공간
            + New Area: Eden(객체들이 최초로 생성되는 공간), Suvivor(Eden에서 참조되는 갹체들이 저장되는 공간)
            + Old Area: New Area에서 일정 시간 이상 참조되는 객체들이 저장되는 공간

        * Native 메서드: 자바외의 다른 언어에서 제공되는 메서드들이 저장되는 공간
        * PC레지스터: Thread들이 생성될때마다 생성되는 공간, Thread가 어떤 부분을 어떤 명령으로 실행할지에 대한 기록, 현재 실행되는 부분의 명령과 주소를 저장

2. Stream
    - SteamAPI는 Java의 Collection에서의 연속된 데이터의 반복 연산을 for문 등을 쓰지 않고, 추상화된 메서드를 통해 무엇(What)을 할 것인지 정의. 즉 FP이다. 스트림을 생성하는 최초연산, 중간의 로직을 구성하는 중간연산, 결과물을 처리하는 최종연산으로 나뉜다. 중간연산의 리턴값은 스트림으로, 계속해서 메서드 체이닝을 해 나갈 수 있다. 최종연산의 리턴값은 스트림이 아니며, 최종연산이 수행되지 않는다면 중간연산 역시 수행되지 않는다.

3. synchronized, volatile, atomic class 차이
    - 셋 모두 thread safe(어떤 함수나 변수, 객체가 여러 스레드에 의해 동시에 접근이 이뤄져도 프로그램의 실행에 문제가 없음)를 만들기 위해 사용
    - volatile는 CPU의 캐시 메모리에 저장하지 않고 반드시 메인 메모리에 저장하기 때문에 변수의 가시성 문제를 해결. 하지만 항상 동시성 문제를 해결하는 것이 아니고, 하나의 스레드만 write를 하고 나머지의 스레드들은 read하는 상황에서만 최신의 값을 보장
    - Atomic 클래스의 경우는 여러 스레드에서 읽기 쓰기 모두 이용할 수 있다. (CAS)
        * CAS(compare-and-swap): CAS방식은 자신이 읽었던 변수의 값을 기억하고 있다가 변경을 완료하기 직전에 읽었던 변수의 값이 그대로인지 확인하고 아니라면 실행을 무산시키는 방식
    - synchronized 경우도 여러 스레드에서 읽기 쓰기 모두 이용할 수 있다. (Lock)

4. string, string buffer, string builder 차이
    - string: immutable, 불변, 한번 생성되면 할당된 메모리 공간이 변하지않음. + 또는 concat메서드를 통해 기존에 생성된 string을 참조하는게 아니라 새로운 문자열을 만든후 그 객체를 참조하도록 함. Thread safe
    - stringbuffer: 각 메서드별로 synchronized, 멀티스레드 환경에서의 동기화 지원
    - stringbuilder: 동기화 미지원

5. Java lambda
    - 람다식이란 익명 함수를 생성하기 위한 식, 함수형 인터페이스를 구현하는 모습으로 사용 
    - 메소드의 구현이 간결해지고 가독성이 올라가며, 함수형 프로그래밍을 바탕으로 병렬 프로그래밍이 가능, 지연 연산으로 향상됭 퍼포먼스
    - 하지만 람다식이 남발되면 오히려 가독성이 떨어지며, 람다식을 재귀로 활용하는경우 까다롭다는 단점
    - ```( 매개변수 ) -> { 실행문 }``` 
    - SAM: 1개의 추상메서드를 가지고있는 인터페이스, 함수형 인터페이스라고도 함. 자바의 람다식은 함수형 인터페이스로만 접근, 람다식으로 만든 객체에 접근하기 위해 사용, Runnable, Supplier, Consumer등이 이에 해당
    
    ```java
    public interface FunctionalInterface {
        public abstract void doSomething(String text);
    }

    FunctionalInterface func = text -> System.out.println(text);
    func.doSomething("do something");
    ```
    
6. GC 동작방식
    - GC는 사용하지 않는 객체를 메모리에서 제거하는 작업
    - 사용중인 객체를 메모리에서 제거 한다면, 프로그램이 정상적으로 실행되지 않을것이기 때문에 사용중인지 아닌지를 구분할 방법이 있어야함
    - 그래서 오래된 객체를 제거하는데 자바는 이 오래됨을 표현하기 위해 힙을 여러 영역으로 나눠둠
    - 처음 생성된 객체는 Young Generation의 일부인 Eden영역에 위치하는데, 이후 이 Eden영역이 꽉차게 되면 Minor GC가 발생하는데, 이때 객체가 다른곳에서 참조되지 않으면 메모리에서 제거됨
    - Eden에서 살아남은 객체는 또다른 Young Generation 의 일부인 Suvivor영역에 이동하게됨. Suvivor는 Suvivor1 과 Suvovir2가 있는데, Minor GC가 발생할때마다 Suvivor1에서 2로, Suvivor2에서 1로 이동하게 되며 그 과정에서 더이상 참조되지 않는 객체는 메모리에서 제거
    - Minor GC동안 Suvovir1,2를 오가며 살아남은 객체는 최종적으로 Old Generation으로 옮겨지며, Old Generation에 있다가 미사용된다고 식별된 객체는 Full GC때 메모리에서 제거됨
    
7. GC 방식
    - Serial GC: 순차적인 GC, single thread
    - Parallel GC: multi thread GC
    - Parallel Old GC: parallel GC를 조금 개선, Old GC 알고리즘이 개선됨
    - CMS GC: GC 과정에서 발생하는 STW(Stop-The-World) 시간을 최소화
    - G1 GC: 큰 힙 메모리에서 짧은 GC 시간을 보장하는 방법

8. JUnit 5 생명주기
    - 메서드 단위 생명주기: 개별 테스트 메서드의 실행 전 새로운 인스턴스가 실행됨
    - 클래스 단위 생명주기(```@TestInstance(Lifecycle.PER_CLASS)```): 테스트중 단 하나의 인스턴스를 생성하며 만약 해당 클래스가 인스턴스 속성을 가진다면, BeforeEach나 AfterEach 메서드를 사용해 이를 초기화 해야함. BeforeAll이나 AfterAll이 Static일 필요가 없게됨
    - BeforeAll -> BeforeEach -> Test -> AfterEach -> AfterAll

9. 모던 자바
    - Concurrent API
        * java.util.conturrent 패키지
        * 동기화가 필요한 상황에서 사용할 수 있는 다양한 유틸리티 클래스들을 제공
        * Locks(상호 배제를 사용할 수 있는 클래스들), Automic(동기화 되어있는 변수), Executors(쓰레드풀 생성, 쓰레드 생명주기 관리 등), Queue(Thread Safe한 FIFO큐), Synchronizer(특수한 목적의 동기화를 처리하는 클래스들)

    - Stream
    - 람다
    - NIO2
        * New Input/Output, 자바7부터 일관성 없는 클래스들의 설계를 바로잡고, 비동기 채널의 네트워크 지원을 강화했음
        * 채널 방식의 비동기로, 블로킹 논블로킹이 모두 지원됨
        * 무조건 버퍼를 활용 해야 하기 때문에, 즉시 처리하는 IO보다는 성능 저하가 발생할 수 있으니 잘 선택 해야함
    
    - Java11 변경점
        * 새로운 String Method추가 - 공백을 제거하는 strip(trim과 다른점은 모든 유니코드 공백문자를 제거, 성능도 빠름), isBlank(비어있거나 공백만 있을때 true), line(라인 단위로 쪼개서 반환하는 스트림) 등
        * java.nio.file.Files 클래스에 유틸 메서드 추가 - wirteString(파일에 문자열을 작성하고 Path를 반환), readString(파일 전체 내용을 읽어 String으로 반환), isSameFile(두 path가 같은 파일을 가리키는지)
        * 람다 파라미터로 var 사용 - Java8에 등장해서 10에 사라졌다가 11에 다시 나옴, 람다식 내에서 타입을 명시 안할때가 많은데 var를 명시 하면서 ```@Nullable```과 같은걸 달아주기 위해
        * Nest 기반 접근 제어 - 논리적으로 같은 클래스를 분리된 클래스로 컴파일 할 수 있음. 다른 클래스의 private 멤버에 getter/setter 없이 접근이 가능하게됨
        * 새로운 가비지 컬렉터 - ZGC, GC 중지 시간을 10ms이상 초과하지 않고, 매우 큰 크기의 범위의 힙까지 처리 가능하게 나옴
        * 새로운 표준 HTTP 라이브러리 - java.net.http 에 HttpClient가 생김. CompatableFuture를 이용한 Non-Blocking request와 reponse, Backpressure 지원, HTTP2 지원 등
        * Flight Recoder - application, jvm, os상에서 발생하는 이벤트들을 기록, 기존 툴에 비해 오버헤드가 낮음

10. 스트림 vs 반복문
    - 스트림의 성능이 반복문에 비해서 더 빠른것은 아니다. 병렬 스트림 또한 마찬가지다
    - 가독성도 적절한 경우에서는 증가하는것이 맞지만, 오히려 더 복잡해지는 경우도 있다
    - 스트림은 람다를 사용하게 되면서 지역변수를 쓸 수 없게되고, 중간 연산 끼리에서 값도 공유되지 않는다
    - 또한 스트림의 모든 원소가 차례로 연산을 거치기 때문에, filter 나 skip같은 중간 연산을 먼저 쓰는게 효율적이다

11. 함수형 프로그래밍
    - 어떻게 할것인지(How)보다 무엇을 할것인지(What)에 포커스를 둠으로써, 거의 모든것을 순수 함수로 나누어 해결함으로, 작은 문제를 해결하기 위한 함수를 작성하여 가독성을 높이고 유지보수를 용이하게 해준다
    - 부수효과가 없는 순수 함수를 1급 객체로 간주하여 파라미터로 넘기거나 반환값으로 사용할 수 있으며 참조 투명성을 지킬수있다
        * 부수효과는 다음과 같이 변화가 발생하는 작업들
        * 변수의 값이 변경, 자료 구조를 제자리에서 수정, 객체의 필드값을 설정, 예외나 오류 발생으로 실행 중단 등
    - 순수 함수는 함수 자체가 독립적이며 Side effect가 없기 때문에 쓰레드 안정성을 보장 받을수있으며, 그로인해 병렬 처리를 동기화 없이 진행 가능
    - 1급 객체란 변수나 데이터 구조 안에 담을 수 있으며, 파라미터로 전달 가능하고, 반환값으로 사용할 수 있으며, 할당에 사용된 이름과 무관하게 고유한 구별이 가능하다
    - 참조 투명성이란 동일한 인자에 대해서 항상 같은 결과를 반환하는것을 말하며, 참조 투명성을 통해 기존의 값은 변경되지 않고 유지된다
    - Java에서 Java8 이후로 StreamAPI, 람다식, 함수형 인터페이스 등으로 함수형 프로그래밍을 지원. 그중 Stream API는 데이터를 추상화하고 처리하는데 자주 사용되는 함수들을 모아둠
    - 자바의 표준 함수형 인터페이스는 반환값과 인수값이 같은 Operator인터페이스, 인수와 반환값이 다른 Function 인터페이스, 인수를 하나 받아 boolean을 반환하는 Predicate 인터페이스, 인수를 받지않고 값을 반환하는 Supplier 인터페이스, 인수를 하나 받고 반환값은 없는 Consumer 인터페이스 등이 있다

# DB & JPA

1. JDBC는 무엇인가?
    - 자바를 이용한 데이터베이스 접속과 SQL 문장의 실행, 그리고 실행 결과로 얻어진 데이터의 핸들링을 제공하는 방법과 절차에 관한 규약
    - 자바 프로그램 내에서 SQL 문을 실행하기 위한 자바 API
    - SQL과 프로그래밍 언어의 통합 접근 중 한 형태
    - JAVA는 표준 인터페이스인 JDBC API를 제공
    - 데이터베이스 벤더, 또는 기타 써드파티에서는 JDBC 인터페이스를 구현한 드라이버(driver)를 제공한다.

2. 영속성, JDBC, MyBatis, JPA, Hibernate, Spring Data JPA
    - 영속성: 데이터를 생성한 프로그램이 종료되더라도 사라지지 않는 데이터의 특성. 영속성을 갖지 않는 데이터는 메모리상에서만 존재하기 때문에, 프로그램이 종료되면 모두 잃어버림. 따라서 파일시스템, DB등을 이용해서 데이터를 영구 저장해서 영속성을 부여해야함
    - 프로그램 아키텍처에 영속성을 부여해주는 계층이 Persistence Layer인데 Persistence Framework를 사용해서 구현
    - Persistence Framework에는 ORM, SQL Mapper가 존재
    - SQL Mapper
        * SQL 문장으로 직접 데이터베이스를 다룸. SQL을 명시 해줘야함
        * 필드를 매핑시키는데에 목적이 있음
        * SQL과 코드가 분리되어있기 때문에 유지보수가 유리
        * SQL쿼리를 그대로 사용하기에 복잡한 JOIN이나 튜닝에 유리
        * 동적 쿼리 생성에 유리
        * 데이터베이스 설정 변경시 수정할 부분이 많고, 특정 DB에 종속
        * MyBatis
    - ORM
        * 데이터베이스 객체를 자바 객체로 매핑 함으로써 객체간의 관계를 바탕으로 SQL 자동생성
        * 관계형 데이터베이스의 관계를 객체에 반영시키는게 목적
        * 메서드 호출로 DB데이터 조작하기 때문에 세밀함이 떨어지고, 복잡한 통계 분석 쿼리를 메서드만으로 만들긴 좀 어려움
        * N+1 문제: 쿼리 1건으로 N건의 데이터를 가져왓는데, 원하는 데이터를 얻기위해 이 N건의 데이터 만큼 쿼리를 다시 하는 경우가 발생하기 쉬움(Mapping때매)
        * JPA: Java Persistence API, 자바 어플리케이션에서 관계형 데이터베이스를 사용하는 방식을 정의한 인터페이스, 인터페이스일뿐 라이브러리가 아님
        * Hibernate: JPA의 구현체, 단순 JPA의 구현체이기 때문에, JPA를 사용한다고 해서 반드시 Hibernate를 사용할 필요는 없음
        * Spring Data JPA: JPA를 쓰기 편하게 만들어둔 모듈(ex> EntityManager 사용 대신에 Repository 사용), JPA를 추상화 한 것
    - JPA
        * Java ORM기술에 대한 API 표준 명세로, 관계형 데이터베이스의 관리는 표현하는 자바 API
        * javax.persistance 패키지로 정의된 API그 자체와, JPQL(Java Persistence Query Language), 객체/관계 메타데이터로 구성
        * 대표적인 구현체가 Hibernate
    - Hibernate
        * JPA의 구현체중 하나로, SQL을 직접 사용하지 않는다고 해서 JDBC API를 쓰지 않는게 아님. Hibernate 메서드 내부에서 JDBC API가 동작중
        * HQL(Hibernate Query Language)라는 쿼리 언어를 포함하는데, SQL과 매우 비슷할 뿐더러 객체지향적이라, 상속, 다형성, 관계등의 강점을 누릴 수 있음

3. JPA 영속성 컨텍스트
    - 영속성 컨텍스트
        * 영속성 컨텍스트란 Entity를 영구 저장하는 환경, EntityManager로 Entity를 저장하거나, 조회하면 EntityManager는 영속성 컨텍스트에 Entity를 보관하고 관리한다
        * 어플리케이션과 데이터베이스 사이에서 객체를 보관하고있는 가상의 DB같은 역할
        * 영속성 컨텍스트는 EntityManager(Session)을 생성할때 하나 만들어진다. 그리고 그 EntityManager를 통해 영속성 컨텍스트에 접근할 수 있고, 영속성 컨텍스트를 관리 할 수 있다
        * 여러 EntityManager에서 하나의 Entity에 접근 할 수도 있다

    - Entity 생명주기
        * new: 영속성 컨텍스트와 전혀 관계가 없는 상태. persist를 통해 merged로 변경
        * merged: 영속성 컨텍스트에 저장된 상태. detach, clear, close를 통해 detached로 변경되거나, remove를 통해 removed로 변경되거나 flush로 db에 반영, db에서 find로 찾아온 Entity도 merged 상태
        * detached: 영속성 컨텍스트에 저장되었다가 분리된 상태. merge를 통해 merged로 변경 
        * removed: 삭제된 상태. persist를 통해 merged로 변경되거나 flush로 db에 반영

    - 영속성 컨텍스트 특징
        * 엔티티를 식별자 값으로 구분하므로 식별자 값이 반드시 있어야함
        * 트랜젝션을 커밋하는 순간 영속성 컨텍스트에 저장된 엔티티를 DB에 반영하는데 이것을 flush라 부름
        * 1차캐시: 영속성 컨택스트 내부의 캐시가 있어, 영속 상태의 엔티티 조회 가능
        * 엔티티의 동일성 보장
        * 트랜젝션을 지원하는 쓰기 지연: 트랜젝션 커밋 전까지 SQL을 모아둿다가, 커밋할때 DB에 보냄

4. JPA 특정 컬럼만 받아오고 싶을때
    - JPQL사용 : ```@Query("select d.id, d.name from Document d")```
    - Mapping Interface 사용:

    ```java
    interface Data {
        String getId();
        String getName();
    }
    ```

    - QueryDSL 사용: SQL, JPQL을 코드로 작성할 수 있도록 도와주는 빌더 API, JPA 크리테이라에 비해서 편리하고 실용적이다. 문자가 아닌 코드로 작성하기 때문에 컴파일 시점에 오류 발견 가능.

5. JPA 패치 전략
    - 연관관계에 있는 Entity를 모두 가져오는것은 Eager (~ToOne 들의 기본)
    - 연관관계에 있는 Entity를 가져오지 않고, getter를 통해 접근할때 가져오는것은 Lazy(~ToMany의 기본). getTeam하면 Team의 프록시가 조회되고, getTeam().getName해야 실제 쿼리를 이용해 Team을 가져옴
    - ManyToOne이 5개가 있는데, 모두 Eager면 조인이 5번일어나며 그러다보면 어플리케이션의 성능저하가 발생할수있음
    - 정말 필요한 사항이 아니라면 Lazy를 사용하라고 함

6. JPA Cascade 옵션
    - CascadeType.RESIST: 엔티티를 생성하고, 연관 엔티티를 추가 했을때, persist()를 수행하면 연관 엔티티도 같이 persist()가 수행. 만일 연관 엔티티가 DB에 저장 되어있다면, 다시 persist()를 하는 것이기 때문에, Detached Entity passed to persist Excpetion 이 발생
    - CascadeType.MERGE: 트랜젝션이 종료되고, detach 상태에서 연관 엔티티를 추가하거나 변경된 이후에 부모 엔티티가 merge()를 수행하면 변경사항 적용. 연관 엔티티의 추가 및 수정이 모두 반영됨
    - CascadeType.REMOVE: 삭제시 연관 엔티티도 같이 삭제
    - CascadeType.DETACH: 부모 엔티티가 detach()를 수행하게되면, 자식 엔티티도 detach()가 수행되어 변경사항이 반영되지 않음
    - CascadeType.ALL: 모든 CascadeType 적용

7. JPA OneToMany, ManyToOne, OneToOne, ManyToMany
    - 연관관계를 매핑하는 어노테이션들
    - 테이블 중심의 모델링이 된다면, 외래키를 가지고 데이터를 찾기때문에 객체지향 스럽지가 못함. 객체 중심으로 관계를 매핑하는게 좋음
    - 실제 테이블에서는 양방향 연관관계(양쪽에서 서로 참조할수있는 관계)가 존재하지 않고, 이는 JPA에서 프로그래밍적으로 사용할수있게 해주는것일뿐임
    - 권장되는 방식은 단방향임. 외래키가 있는 테이블을 대변하는 엔티티가 연관관계의 주인. 역방향 참조가 필요한 경우가 아니라면 단방향
    - ```@JoinColumn``` : FK를 어떤 컬럼에 매핑시킬껀지. 이게 있는쪽이 연관관계의 주인
    - ManyToOne
        * 여러개의 테이블이 하나의 테이블과 연관 관계를 맺을때 사용
        * Memeber가 있고 Order가 있다면, 하나의 Member는 여러개의 Order를 가질수있기 때문에, Order관점에서 보면 ManyToOne
        * 따라서 Order 테이블에 ManyToOne과 JoinColumn을 사용해 Member FK 를 위한 필드를 만들어 매핑
        * Order 테이블에 외래키가 존재 하므로 Order테이블이 연관관계의 주인
    - OneToMany
        * 하나의 테이블이 여러개의 테이블과 연관 관계를 맺을때 사용
        * Memeber가 있고 Order가 있다면, 하나의 Member는 여러개의 Order를 가질수있기 때문에, Member관점에서 보면 OneToMany
        * 따라서 Member 테이블에 ```@OneToMany(mappedBy = "member")```와 같이 mappedBy를 통해 Order테이블에서 어떤 속성으로 매핑되는지를 표시 해줘야함(member가 Order의 필드명임). 그리고 이럴땐 관례로 ArrayList로 초기화를 해서 NPE를 방지하는게 좋다
    - 일대다는 1이 연관관계의 주인이지만, 외래키가 다쪽에 있어야하므로 이상하게 됨. 일대다 단방향보단 다대일 양방향이 나음
    - 일대일 관계는 외래키를 어디 두냐에 따라 달라짐
        * 주 객체에 외래키: 주 객체에 외래키를 두어, 주 객체가 대상 객체에 대한 참조를 가지는 것처럼 주 테이블에 외래키를 두고 대상 테이블을 찾음. JPA 매핑이 편하며, 주 테이블만 조회해도 대상 테이블에 데이터가 있는지 확인이 가능. 값이 없을경우엔 외래키에 Null이 허용됨
        * 대상 객체에 외래키: 대상 테이블에 외래키가 존재하여, 주 테이블과 대상 테이블을 일대일이 아닌 일대다로 변경해도 테이블 구조가 유지됨. 지연로딩을 해도 항상 즉시 로딩이 되는 문제
    - 양방향 연관관계에서 주의할것
        * 객체에서의 양방향 연관관계의 표현과, DB에서의 양방향 연관관계의 표현은 다르다
        * 객체에서의 양방향 연관관계의 표현은 서로의 객체를 멤버로 들고 있음으로써(단방향 연관관계를 양쪽에 다 만들어주는것) 표현
        * DB에서의 양방향 연관관계의 표현은 외래키 하나면 충분하다(조인을 하면 되기 때문)
        * 다 쪽이 연관관계의 주인이 되는것을 명심하고, 다쪽에 ```@JoinColumn```, 일쪽엔 ```mappedBy```를 활용
        * 연관관계의 주인쪽에 값을 입력해야 하며, 이왕이면 순수 객체 상태를 고려해 양쪽에 데이터를 모두 넣어주자
        * 무한루프를 주의해야한다. lombok이 만들어주는 toString이나, JSON 생성 라이브러리를 쓰면 무한루프에 빠지게 되므로, 엔티티를 직접 반환하지말고 DTO를 통해 반환하자

8. DB랑 엮인부분 테스트는 어떻게? DB 모킹은 어떻게 해서 테스트?
    - ```@DataJapTest```
        * Test Class에 ```@DataJapTest``` 선언
        * JPA 관련된 Component만 로드
        * 테스트 종료후 롤백이 같이되서 테스트할때 들어간 값에 대해서 걱정하지 않아도 됨

    - Test Fixture 활용
        * SUT(System Under Test) 를 실행하기 위해 필요한 모든 것을 테스트 픽스쳐라고 한다. Fixtrue 는 테스트를 위해 필요한 모든 자원을 생성하며, 이를 테스트 가능한 상태로 세팅해둔다
        * Fixture Factory같은 라이브러리를 활용해서 테스트에 사용할 엔티티등을 만듦
        * Mock에서 반환값등으로 Test Fixture가 반환 되도록 사용

    - Mock 활용
        * JPA Repository를 Mocking(```@Mock```)
        * 적절한 given & willReturn으로 세팅
        * 테스트
        * Repository를 사용하는 Service를 테스트 하고 싶은 경우 해당 서비스에 ```@InjectMocks``` 사용

9. 식별 비식별 관계
    - 식별 관계: 외래키를 기본키로 사용하는 관계
    - 비식별 관계: 외래키를 기본키로 사용하지 않고, 일반 속성으로 취급하는 관계


10. JNDI
    - Java Naming and Directory Interface
    - Java로 작성된 어플리케이션에 이름 지정 및 디렉토리 기능을 제공하는 API
    - 데이터베이스와 연결된 커넥션을 미리 만들어 저장해두고 있다가, 필요할때 저장된 공간(pool)에서 가져다 쓰고 반환하는 기법
    - 커넥션풀이 있기 때문에 사용자 요청시마다 드라이버 로드 & 커넥션 객체 생성 및 종료 같은 작업을 하지 않아도 됨

11. DataBase에서 Index란?
    - Table에 대한 동작 속도를 높여주는 자료구조로서 빠른 검색을 가능하게 해준다
    - 지정한 칼럼들을 기준으로 메모리영역에 목차를 생성 하는것
    - update, insert, delete의 성능이 희생되는 대신 select는 빨라질것
    - 인덱스 키는 길수록 성능상에 이슈가 있음
    - 1개의 컬럼으로만 인덱스를 할것이면 중복도가 낮은(카디널리티카 높은)걸 잡아야 하며, 여러개를 하더라도 카디널리티 순으로 해야함
    - 인덱스 자료구조
        * Hash Table: 컬럼의 값으로 생성된 해시를 기반으로 인덱스 구현, 시간복잡도가 O(1)이라 매우 빠름, 부등호와 같이 연속된 데이터를 위한 순차 검색은 안됨
        * B+ Tree: 자식 노드가 2개 이상인 B-Tree를 개선, B-Tree의 리프노드들을 링크드리스트로 연결하여 순차 검색을 용이하게 함, 시간복잡도가 O(logN)이지만 자주 사용

12. DB Transaction 사용하는 이유
    - 트랜잭션(Transaction)은 데이터베이스의 상태를 변환시키는 하나의 논리적 기능을 수행하기 위한 작업의 단위 또는 한꺼번에 모두 수행되어야 할 일련의 연산
    - 트랜잭션은 DB 서버에 여러 개의 클라이언트가 동시에 액세스 하거나 응용프로그램이 갱신을 처리하는 과정에서 중단될 수 있는 경우 등 데이터 부정합을 방지하고자 할 때 사용
    - 하나의 트랜잭션은 Commit되거나 Rollback된다
    - 트랜잭션 성질 4가지
        * Atomicity(원자성): 트랜잭션의 연산은 데이터베이스에 모두 반영되든지 아니면 전혀 반영되지 않아야 함. 트랜잭션 내의 모든 명령은 반드시 완벽히 수행되어야 하며, 모두가 완벽히 수행되지 않고 어느하나라도 오류가 발생하면 트랜잭션 전부가 취소되어야 함
        * Consistency(일관성): 트랜잭션이 그 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환. 시스템이 가지고 있는 고정요소는 트랜잭션 수행 전과 트랜잭션 수행 완료 후의 상태가 같아야함
        * Isolation(독립성,격리성): 둘 이상의 트랜잭션이 동시에 병행 실행되는 경우 어느 하나의 트랜잭션 실행중에 다른 트랜잭션의 연산이 끼어들 수 없고, 실행중인 트랜잭션은 완전히 완료될 때까지 다른 트랜잭션에서 수행 결과를 참조할 수 없다
        * Durablility(영속성,지속성): 성공적으로 완료된 트랜잭션의 결과는 시스템이 고장나더라도 영구적으로 반영되어야 한다

13. DB Transaction 격리 수준
    - Read Uncommitted
        * 더티리드를 가능하게 하는 격리 수준
        * 더티 리드: 더티 페이지(메모리에는 변경이 되었지만, 디스크에는 아직 변경이 되지 않은 데이터)에 있는 데이터를 검색. 커밋 되지 않은 데이터를 리드하기 떄문에, 더티리드 후 더티페이지가 롤백되면 잘못된 데이터를 읽어온것
    
    - Read Committed(기본)
        * 더티리드를 방지해 잘못된 데이터를 읽어오는 경우가 발생하지 않게함. 단 이 격리 수준에서는 반복되지 않은 읽기가 발생할 수 있다
        * 반복되지 않은 읽기(Unrepeatable Read)
            * 1번 세션이 트랜젝션을 걸고 A 테이블에 대해 SELECT를 실행(아직 COMMIT은 되지 않은 상태)
            * 2번 세션에서 다시 A 테이블에 데이터를 UPDATE한다(바로 실행이 완료된다)
            * 1번 세션에 대해 다시 A테이블에 대해서 SELECT를 실행
            * 1번 세션을 COMMIT
            * 1번 세션의 처음 SELECT와 두번째 SELECT의 결과가 다르다. 이것이 반복되지 않은 읽기 이며, 트랜잭션중 데이터가 변경되면 큰 문제가 발생한다

    - Repeatable Read
        * 공유 잠금(SELECT를 통해 발생하는 잠금)이 걸려도 데이터의 변경을 막아줘 반복되지 않은 읽기의 문제점을 방지함. 하지만 팬텀 읽기(가상 읽기)의 문제가 발생
        * 팬텀 읽기(Phantom Read)
            * 1번 세션의 격리 수준을 REPETABLE READ로 변경
            * 1번 세션에서 트랜잭션을 걸고 A 테이블에 SELECT(COMMIT하지 않은 상태)
            * 2번 세션에서 A 테이블에 대한 UPDATE작업이 완료되지 못함(반복되지 않는 읽기 방지)
            * 2번 세션에서 A 테이블에 대한 INSERT 작업을 실행(바로 완료됨)
            * 1번 세션에서 A 테이블에 대한 SELECT(COMMIT하지 않은 상태)
            * 1번 세션을 COMMIT
            * 1번 세션의 첫번째, 두번쨰 SELECT의 로우 숫자가 다르다. 존재하는 데이터의 변경은 불가능 하지만 추가가 가능한 상황이 팬텀 읽기이다

    - Serializeable
        * 팬텀 읽기를 방지 할 수 있는 격리 수준으로, 공유 잠금이 걸린 테이블에 대한 데이터 변경, 추가 작업이 되지 않는다

    - Snapshot
        * Serializeable과 동일한 격리 수준을 보여주지만, 잠금이 걸린 테이블에 대한 데이터 변경, 추가작업이 가능하다
        * 잠금이 걸린 테이블에 대한 변경, 추가작업은 tempDB에 관리되며 잠금이 풀린 즉시 원 테이블에 작업이 이뤄진다

    - Read Committed Snapshot
        * Snapshot과는 달리, 커밋된 데이터에 대해서는 최신 데이터 버전으로 읽을 수 있는 격리 수준

14. 데이터베이스 정규화
    - 데이터베이스의 설계를 재구성하는 테크닉. 정규화를 통해 불필요한 데이터를 없앨 수 있고, 삽입, 갱신, 삭제시 발생하는 이상현상을 방지
    - 이상현상
        * 삭제 이상: 튜플 삭제시 같이 저장된 다른 정보까지 연쇄적으로 삭제
        * 삽입 이상: 튜플 삽입시 특정 속성에 해당하는 값이 없어 NULL을 입력해야하는 상황
        * 갱신 이상: 튜플 수정시 중복된 데이터의 일부만 수정됨
    - 1차 정규화: 각 Row마다 칼럼의 값이 1개씩 있어야함. 칼럼이 원자값을 가진다고도 함
    - 2차 정규화: 모든 테이블의 값이 완전 함수적 종속. 기본키중에 특정 컬럼에만 종속된 컬럼이 없어야 함
    - 3차 정규화: 모든 테이블의 값이 이행적 함수 종속이 없어야함. 기본키 이외의 다른 컬럼이 그 외 다른 컬럼의 값을 결정할수 없어야함
    - BCNF: 3차 정규형을 만족하면서, 모든 결정자가 후보키 집합에 속한 정규형
        * 후보키: 슈퍼키중에 최소성을 만족
        * 슈퍼키: 각 행을 유일하게 식별할 수 있는 하나 또는 그 이상의 속성들의 집합

15. NoSQL
    - 스키마 없음, 관계 없음
    - 관계형 모델을 사용하지 않기 때문에 테이블간의 조인 기능이 없음
    - 관계형 데이터베이스에서 지원하는 Data 처리 완결성이 보장되지 않음
    - Key - Value: 데이터가 Key-Value 쌍으로 저장되는 단순한 형태의 솔루션(Redis, ETCD)
    - Wide Columm : Key-Value 에서 발전된 형태의 Columm Family(Column의 값이 다시 여러개의 Column의 Map으로 구성) 데이터 모델(HBase, Cassandra 등), 테이블을 가지고 있지만, 테이블의 각 로우는 다른 컬럼을 가질 수 있음
    - Document: JSON, XML등과 같은 Collection 데이터 모델 구조(Mongo DB 등). 각 엔티티를 하나의 도큐먼트로 저장. 각 도큐먼트는 다른 구조를 가질 수 있음
    - 데이터가 중복되기에 불안정한 측면이 있지만, 자주 변경되지 않는데이터에서 강점을 가짐
    - SQL이 수평확장이 안되는 대신(데이터가 관계적으로 저장 되므로), NoSQL은 가능
    - 정확한 데이터 구조를 알 수 없거나, 변경/확장 될 수 있는 경우, 읽기 처리를 자주하지만 데이터 변경은 자주 이뤄지지 않는 경우, db 수평 확장이 필요한 경우 유리
    - BASE
        * Basically Available: 가용성, 데이터는 항상 접근 가능, 다수의 스토리지에 복사본 저장
        * Soft-state: 독립성, 노드의 상태는 외부에서 전송된 정보를 통해서 상태가 결정
        * Eventually Consistency: 일관성, 일정 시간 경과시 데이터의 일관성이 유지됨

    - CAP - C,A,P 속성중 많아야 2개만 만족할수있음
        * Consistency: 다른 서버에서도 가장 최근에 쓰여진 데이터가 읽혀야됨
        * Availability: 보낸 요청에 대해서는 응답을 줄 수 있어야함
        * Partition tolerance: 서버간의 통신에서 설령 네트워크가 끊긴 수준의 오류가 있더라도 시스템이 동작 해야함
        * NoSQL이 여기서 Partition tolerance를 좀 더 중요한 가치로 만들어진것

16. DB락의 종류 및 설정 레벨
    - 공유락: 트랜젝션이 읽기를 할때 사용하는 락. 같은 공유락 끼리는 동시에 접근 가능. 배타락의 접근을 막음
    - 배타락: 트랜젝션이 쓰기를 할때 사용하는 락. 데이터를 읽고 쓸수있음. 이 락이 끝나기전의 모든 접근을 막음. 배타락은 다른 트랜잭션이 수행되고 있는 데이터에 대해서 접근해 락을 걸 수 없음
    - 락 설정 레벨
        * 데이터베이스: 전체 DB 기준으로 락. 1개 세션이 하나의 DB에 접근. DB전체에 영향이 가므로 DB업데이트 같은 작업에서만 사용
        * 파일: 데이터베이스 파일 기준으로 락. 테이블과 같이 실제 데이터가 쓰여지는 물리적 저장소에 락이 걸리므로, 파일 전체를 백업할때 사용
        * 테이블: 테이블 기준으로 락. 전체 테이블에 대한 변경이 있을때 사용. DDL 사용할때 쓰이는 락
        * 페이지와 블럭: 파일을 구성하는 페이지와 블럭 기준으로 락
        * 컬럼: 컬럼 기준으로 락. 락 설정 및 해제시 리소스가 많이쓰여 자주 사용되지는 않음
        * 행: 행 수준의 락. 가장 많이 사용

17. DB 클러스터링 & 레플리케이션
    - 레플리케이션
        * 여러개의 DB를 권한에 따라 수직적인 구조로 구축하는 방식(Master - Slave)
        * 비동기 방식으로 노드들간의 데이터를 동기화
        * 비동기 방식으로 데이터가 동기화 되어 지연시간이 거의 없는 대신, 노드들간의 데이터가 동기화 되지 않아서 일관성 있는 데이터를 얻지 못할수도 있다
    - 클러스터링
        * 여러개의 DB를 수평적인 구조로 구축하여 Fail Over한 시스템을 구축하는 방식
        * 동기 방식으로 노드들간의 데이터를 동기화
        * 1개의 노드가 죽어도 다른 노드가 살아있어서 시스템을 장애 없이 운영할수있지만, 노드들간의 데이터에 동기화 하는 시간이 필요하므로 레플리케이션에 비해 쓰기 성능이 떨어짐 

18. Inner Join / Outer Join
    - Inner Join: 교집합을 만들때 사용, 두 테이블에 같이 있는 데이터만 나옴
    - Outer Join: 합집합을 만들때 사용
        * Left Outer Join: 왼쪽에 있는 모든 데이터와, 오른쪽에 같이 있는 데이터
        * Full Outer Join: 양쪽 모두의 합집합. 한쪽에만 있는 데이터는 반대쪽 데이터가 Null로 나옴

19. Hot Data vs Cold Data
    - Hot Data: 자주 사용되는 데이터. 즉시 엑세스 해야하는 데이터.   
    - Cold Data: 드물게 사용되거나, 아예 사용되지 않는 데이터. 빠르게 엑세스 할 필요가 없음. 

20. DB 마이그레이션시 어떻게 플랫폼 호환성을 확보 할것인지
    - 일단 기존에 사용하던게 MyBatis같은 SQL Mapper인지, 아니면 Spring Data JPA같은 ORM인지에 따라서 DB전환시 고쳐야할 범위가 달라진다고 생각함
        * SQL Mapper라면 전체 쿼리를 다 바꿔야 하겟지만, ORM이라면 상대적으로 바꿀 부분이 적을것임. 그래서 일단 ORM으로 변경
        * 특히 Spring Data JPA같은경우 Spring Data의 하위 프로젝트들은 CRUD 인터페이스가 동일하기 때문에 상대적으로 쉽게 변경 할 수 있을것(Spring Data JPA -> Spring Data MongoDB)
    - 그 다음에 마이그레이션 할 DB와 원래 DB 양쪽 모두 커넥션을 만들어서 Test Case를 작성, 양쪽 DB 모두에 대해 삽입 삭제등을 확인하며 동일하게 동작하는지 확인
    - Repository Class가 DB종류마다 하나씩 나오겟지만, 이를 공용 인터페이스를 하나 둬서, 그 인터페이스를 따르게 구현 한다음, 그 인터페이스를 참조해 DB를 접근하는 Class를 하나 만들고, 그 Class에서 현재 연결된 DB 커넥션에 따라 다른 Repository class가 불리도록 하면 어떨까 함


21. ```@Transactional```
    - JPA에서 트랜젝션을 지원할 수 있는 어노테이션
    - rollbackFor 속성을 이용해서 특정 Exception이 발생하면 rollback을 수행 할수있음 (default는 Runtime Exception - Unchecked Exception과 Error)
    - 동작 과정
        * Java에서 데이터베이스의 트랜잭션을 시작하는 유일한 방법은 JDBC를 통하는 방법뿐임. Connection을 맺고 setAutoCommit을 false로 두어 트랜젝션 관리를 직접하게 하고 commit하거나 롤백
        * 스프링이 Transactional 어노테이션이 달린 public 메서드에 대해서 내부적으로 데이터베이스 트랜잭션 코드를 실행해줌. 위에서랑 똑같이 Connection 가져와서~
        * Transactional 어노테이션을 발견하면 그 빈의 다이나믹 프록시를 만들고, 그 프록시 객체가 트랜잭션 메니저에 접근해서 트랜젝션을 열고 닫도록 요청하는데, 그 트랜젝션 매니저가 JDBC방식으로 코드를 실행
    - Transaction 전파 레벨
        * REQUIRED: 기본적으로 해당 메서드를 호출한곳에서 벼롣의 트랜잭션이 설정되어 있지 않다면, 새로 트랜잭션을 시작. 이미 트랜젝션이 설정되어 있다면 기존 트랜잭션내에서 로직 실행
        * REQUIRES_NEW: 매번 새로운 트랜잭션을 시작. 이미 트랜잭션이 설정되어있다면, 기존 트랜잭션을 대기상태로 전환하고 자신의 트랜잭션 실행. 새 트랜잭션 안에서 예외가 발생하더라도 호출한곳에는 롤백이 전파되지 않음
        * NESTED: 기본적으론 REQUIRED로 동작하지만, SAVEPOINT를 지정한 시점까지 부분 롤백이 가능. 데이터베이스가 SAVEPOINT 기능을 지원 해야함
        * Transactional이 걸린 메서드를 호출한곳과 별도의 쓰레드에서 Transational 메서드가 실행된다면, 전파 레벨과 상관없이 무조건 별도의 트랜잭션이 생성된다. Spring은 내부적으로 트랜젝션 정보를 ThreadLocal 변수에 저장하기 때문에, 다른 쓰레드로 

22. Cassandra
    - Key-Space -> Column family -> Row -> Column name : Column Value 의 구조
    - 하나의 row는 여러 column을 가질 수 있고, 각각의 row는 같은 column을 가질 필요는 없고, 각 row는 unique key를 가지는데 이를 이용해서 파티셔닝을 한다고 함
    - NoSQL 이기 떄문에 관계가 없음
    - Map<RowKey, SortedMap<ColumnKey,ColumnValue>>와 같은 형태로 저장된다고함
    - Schemaless(Schema-free)기 때문에 데이터 구조가 어떤 형태를 가질지, 어떤 필드를 가질지 미리 저장할 필요가 없으며, 계속해서 필드의 추가 변경이 이뤄지는 경우 유용함
    - 데이터 모델링을 한 후 복잡한 join을 사용하는것이 아닌 원하는 쿼리를 모델링 한다음 데이터를 제공 하도록 함
    - CQL(Cassandra Query Language)라는 SQL과 유사한 쿼리 인터페이스가 제공됨
    - CQL Key 종류
        * partition key - 데이터를 준산 저장하기 위한 unique 한 key, 특정 table을 구성할때 반드시 1개 이상 지정 되어야 하며 여러개가 지정 될 수도 있음
            + partition key가 1개: 해당 partition key로 지정된 CQL Column의 value가 실제 Cassandra Data layer의 row key로 저장
            + partition key가 여러개: 각 partition key로 지정된 CQL Column의 value들을 : 함께 조합한 값들이 row key로 저장
        * cluster key - Cassandra Data layer 의 모든 row는 정렬된 상태로 저장되는데, cluster key가 정렬 기준임. cluster key가 없는 경우엔 CQL Column의 name이 그대로 Cassandra Data layer의 Column name이 됨
        * primary key - CQL table에서 각 row를 각자 unique하게 결정해주는 기준 역할, 1개 이상의 partiton key와 0개 이상의 cluster key로 구성
        * composite key - 1개 이상의 CQL Column들로 이뤄진 Primary key를 composite key / compound key라고 부름
    - Cassandra Ring
        * Cassandra 는 모든 노드가 동등한 ring 구조, ring을 구성하는 각 노드에 data를 분산해서 서장
        * partition key의 hash 값을 기준으로 data를 분산
        * 처음 각 노드가 ring에 참여하게 된다면 conf/cassandra.yaml에 정의된 각 설정을 통해 각 노드마다 고유의 hash값 범위를 부여받음
        * 데이터의 partition key의 hash를 계산해서 해당 데이터가 어느 노드에 저장되어있는지 알고 조회 가능, 이렇게 계산된 hash값을 token이라고 부름
        * 스케일링 할때는 이 링에 노드가 추가되는것임
    - 분산
        * Cassandra는 마스터 없이 동작, 데이터 분산이나 복구를 관장하는 별도 서버가 없음
        * 모든 데이터가 비교적 균일하게 노드에 분산되서 저장함
        * partition key(row key)를 token으로 변환해주는 모듈을 partitioner라 부르는데 3가지(Random Partitioner, Murmur3 Partitioner, BOP, Murmur3이 기본)가 존재
    - Replication
        * 처음 Key Space 생성할때 Replication 배치 전력과 그에 맞는 복제 개수등을 정할 수 있음. no single point of failure를 위해서는 3개 이상 복제 하라고 함
        * 2가지 Replication Strategy가 있음(Simple Strategy - 하나의 데이터 센터, NetworkTopology Strategy - 2개 이상의 데이터센터) 
    - raw key로 정렬 불가능, 모든 노드가 동일한 역할을 하므로 데이터 일관성 문제 발생 가능, 쓰기성능과 확장성이 뛰어남

23. HBase
    - Columnar DB, Hadoop File System 위에 구축되어있음. 분산환경에 적합하게 수평 확장이 가능
    - Hadoop Ecosystem의 일부로 실시간 읽기/쓰기를 HDFS에 가능하게 함
    - Table(Row의 집합), Column Family(컬럼 그룹, 모든 컬럼패일리의 멤버는 같은 접두사),Column 의 구조
    - HMaster(Region Server 모니터링, 배정, 메타데이터 관리 등), Zookeeper(Region Server 상태 추적), Region Server(Region별 데이터 제공 및 관리) 로 구성
    - HMaster: Region 배치와 테이블의 생성/삭제 작업 처리, Region Server의 복구 및 로드밸런싱에 관여해서 Region을 재 할당
    - Zookeeper: 각 노드의 상태 정보를 Heartbeat 기반으로 추적하는 분산 코디네이터
    - Region: HBase 테이블의 로우들을 수평분할하고 이를 하나로 묶은것, 하나의 startKey와 endKey사이의 모든 Row를 포함, 하나의 Region Server는 약 1000개 Region 수용 가능
    - Region Server: Region을 가지고 있는 서버. DataNode에서 실행됨(HDFS 블록을 저장하는 책임이 있는 주체)
    - raw key로 정렬 가능, Master가 데이터 일관성 보장, 1개 노드에 쓰기가 몰릴 수 있어 쓰기 성능 저하


# Network & Server & Spring Framework

1. 쿠키와 캐시(Cache)와 세션(Session)의 공통점과 차이점은?
    - 쿠키 : 브라우저를 사용하는 환경(로컬 컴퓨터에), 로그인정보같이 유저가 다시 서버에 요청하기엔 비효율적인 정보를 저장
    - 캐시 : 브라우저를 사용하는 환경(로컬 컴퓨터에), 서버에서 받은 데이터를 저장한 파일. 쿠키와 동일하지만 이미지처럼 재사용되거나 용량이 큰 리소스를 저장
    - 세션 : 세션은 서버에 저장되고 브라우저 단위로 관리된다. 쿠키나 캐시에 비해 보안성이 좋다.

2. Request 전송 방식에는 어떤 것들이 있는지 아시나요?
    - GET 방식 : 데이터 가져오기, SELECT, URL의 쿼리문자열에 데이터를 같이 전달하는 방식으로 데이터 길이에 제한이 있다.
    - POST 방식 : 데이터 삽입하기, INSERT, 바디 데이터를 넣어 보내기 때문에 데이터 길이에 제한이 없다. 하지만, Get에 비해 다소 느리다.
    - DELETE 방식 : RESTFUL에서 삭제 기능을 할 때 주로 사용된다.
    - PUT/PUSH 방식 : RESTFUL에서 수정 작업을 할 때 주로 사용된다.

3. RESTFUL이란?
    - REST란 REpresental State Transfer의 약자, 자원을 표현하여 상태를 전달한다는 뜻으로, 웹에 있는 자원을 HTTP를 통하여 직관적으로 전달하기 위한 간단한 인터페이스
    - REST API의 구성
        * 자원 - URI
        * 행위 - HTTP Method
        * 행위의 내용 - HTTP Message Pay Load

    - REST의 특징
        * Uniform Interface: URI로 지정한 리소스에 대한 조작을 통일되고 한정적인 인터페이스로 수행하는 아키텍처 스타일
        * Stateless: 무상태성, 작업을 위한 상태 정보를 저장하고 관리하지 않음. 세션정보나 쿠키를 별도로 저장하고 관리하지 않기 때문에 API는 단순히 들어오는 요청만 처리하면된다.
        때문에 서비스의 자유도가 높고 서버에서 불필요한 정보를 관리하지 않아 구현이 단순해짐
        * Cacheable: 캐시가능. HTTP라는 기존 웹표준을 그대로 사용하기 때문에, 웹에서 사용하는 기존 인프라를 그대로 활용이 가능하며, 이로인해 HTTP가 가진 캐싱기능을 할수있음
        * Self-descriptiveness: 자체 표현 구조로, REST API 메시지만 보고도 이를 쉽게 이해 할 수 있다
        * Client - Server: REST서버는 API제공, 클라이언트는 사용자 인증이나 컨텍스트를 직접 관리하는 구조로 각각의 역할이 확실하게 구분되어 서로 개발해야할 내용이 명확하고 의존성이 적음
        * 계층형 구조: REST서버는 다중 계층으로 구성될수있으며, 보안, 로드밸런싱, 암호화 계층을 추가해 구조상의 유연성을 둘 수 있고, PROXY, 게이트웨이 같은 네트워크 기반의 중간매체를 사용할수있다

    - REST API 디자인 가이드
        * URI는 정보의 자원을 표현해야 한다(리소스명은 동사보다는 명사를 활용)
        * 자원에 대한 행위는 HTTP Method(GET, POST, PUT, DELETE)로 포현한다 
        * / 구분자는 계층관계를 나타내는데 활용
        * URI의 마지막 문자로 / 를 포함하지 않는다
        * ```-```는 URI가독성을 높이는데 활용
        * _ 은 URI에 사용하지 않는다
        * URI엔 소문자가 적합하며, 파일 확장자는 URI에 포함하지 않는다


4. Spring에서 DI란 무엇인지 아시나요? IoC란? 
    - DI는 Dependency Injection(의존성 주입)의 약자로, 객체들 간의 의존성을 줄이기 위해 사용되는 Spring의 IOC 컨테이너의 구체적인 구현 방식입니다. 객체를 직접 생성하는 게 아니라 외부에서 생성한 후 의존 관계를 setter나 생성자 인수를 통해 주입하는 방식. 모듈간의 결합도가 낮아지고 유연성이 높아짐
    - Inversion Of Control, 제어의 역행이라는 뜻으로, 인스턴스의 생성 및 소멸을 개발자 대신 스프링 컨테이너가 한다. 그외 제어권을 프레임워크에서 가져간다는 말로도 쓰인다.
    - Spring에서는 객체가 생성된 이후 IOC 컨테이너에 의해 의존성이 주입되어, 의존성 객체의 메서드를 사용하는 방식으로, Spring Framework가 모든 의존성 객체들(Bean)을 만들어주고 필요한곳에 주입 시켜줌(DI). 제어의 흐름을 개발자가 컨트롤 하는게 아닌 Spring에 맞겨 처리하게 됨(IOC)
    - 의존성 객체(Bean)들은 기본적으론 싱글톤의 특성을 띄지만(Spring이 만들어주고 있어서), Prototype 빈은 매 요청시마다 생성됨

5. Spring의 AOP란?
    - AOP는 Aspect Oriented Programming 관점 지향 프로그래밍의 약자로, 기존의 OOP(객체 지향 프로그래밍)에서 기능별로 class를 분리했음에도 불구하 고, 여전히 로그, 트랜잭션, 자원해제, 성능테스트 메서드 처럼 공통적으로 반복되는 중복코드가 여전히 발생하는 단점을 해결하고자 나온 방식
    - 공통 코드를 "횡단 관심사"라 표현하며 개발코드에서는 비지니스 로직에 집중하고 실행시에 비지니스 로직 앞, 뒤 등 원하는 지점에 해당 공통 관심사를 수행할 수 있게 함으로서 중복 코드를 줄일 수 있는 방식입니다
    - Proxy 기반으로 어드바이스(횡단 관심사를 구현하는 Aspect의 메서드)의 대상 객체(얘도 결국 스프링 컨테이너에 등록된 빈)마다 프록시 객체가 만들어져서, 실행 시점에 프록시는 해당 객체 호출을 가로채고 재상 메서드에 적용할 어드바이스를 실행
    - ```@Aspect``` 어노테이션으로 Aspect를 지정하고 ```@Pointcut```으로 포인트컷 식을 지정한 후, ```@Before```, ```@After```, ```@Around``` 등의 어노테이션으로 어드바이스를 지정해서 설정

6. 비동기와 동기, 블록과 논블록
    - 동기: A라는 행위와 B라는 행위가 순차적으로 작동하면 동기. A가 B를 관찰하는 행위라면 동시에 일어나도 동기
    - 비동기: 인과 관계가 있는 작업 A,B가 동시에(혹은 순차적이지 않게) 실행되고 있다면 비동기. 다되면 콜백으로 알려줌
    - 블록: A라는 함수를 호출했을때 기대하는 모든 행위를 모두 끝마칠때까지 기다렸다가 리턴되면 블로킹
    - 논블록: A라는 함수를 호출했을때 기대하는 어떤 행위를 요청하고 바로 리턴되면 논블로킹
    - 동기와 비동기는 동시성에 관한 이야기 이고, 블로킹/논블로킹은 동시성과는 무관한 이야기

7. Spring Framework에서의 요청 처리 순서(브라우저부터 설명)
    - 클라이언트(브라우저)에서 URL로 접속하여 정보를 요청
    - DispatcherServler이 해당 요청을 받아, 해당 요청을 매핑한 컨트롤러가 있는지 확인
    - Handler Mapping에서 적절한 Controller에게 처리 요청
    - Controller 에서 해당 요청 처리 후, 결과를 출력할 View의 이름을 DispatcherServlet에게 반환
        * 이 과정에서 컨트롤러는 해당 요청을 처리할 적절한 Service를 사용 할 수 있고, 해당 Service는 DAO를 통해 DB와 접근도 할 수 있음. 이것이 MVC 패턴
        * 만약 ```@RestController```로 컨트롤러가 정의 되어 있다면, View로 출력되는것이아니라 Message Convertor에 적절한 메시지 형식 (application/json, text/plain)등으로 바뀌고 이것이 HTTPResponse에 직접 쓰여 반환되게 된다. 밑의 View 검색 절차는 필요하지 않다

    - DispatcherServelet에서 받은 View이름을 바탕으로 적절한 View를 ViewResolver를 통해 검색
    - ViewResolver가 처리 결과를 View에게 송신
    - View는 처리 결과를 담아 DispathcerServler에게 송신
    - DispathcerServlet이 클라이언트에게 최종 결과 출력

8. HTTP 요청 흐름 (웹브라우저에서의 요청)
    - 브라우저에서 먼저 URL에 적힌 값을 파싱하여, HTTP 요청 메세지를 만든다. 만든 메세지를 웹 서버로 전송하는데, 이때 웹 브라우저 직접 전송을 하는것이 아니라 OS에 보내주십쇼~ 하고 의뢰를 하게 된다. OS는 DNS서버를 조회해서 Host이름을 보내야 할 IP 주소로 변환하게 된다.
    - 프로토콜 스택(운영체제에 내장된 네트워크 제어용 소프트웨어, TCP/IP 계층)과 LAN 어댑터 에서 브라우저로부터 메시지를 받는다. 브라우저로부터 받은 메시지를 패킷 속에 저장한다. 그리고 수신 주소를 제어정보에 덧붙인다. 그 다음, 패킷은 LAN 어댑터에 넘긴다. LAN 어댑터는 패킷을 전기 신호로 변환시켜 LAN 케이블에 송출하게 된다.
    - 허브, 스위치, 라우터 에서 LAN 어댑터로부터 송신한 패킷을 수신한다. 라우터는 패킷을 ISP에 전달, 인터넷으로 들어가게 된다.
    - 액세스 회선, ISP : 액세스 회선이라는 것은 인터넷의 입구에 있는 통신 회선이다. 액세스 회선에 의해 통신사용 라우터(POP, Point Of Presence)까지 운반된다. POP를 거쳐 인터넷의 핵심부로 들어가게 된다. 고속 라우터들 사이로 목적지까지 패킷이 흘러가게 된다.
    - 방화벽, 캐시서버 : 인터넷 핵심부를 통과한 패킷은 목적지의 LAN에 도착하게 된다. 방화벽이 먼저 패킷을 검사한 후, 캐시서버로 보내서 웹 서버까지 갈 필요가 있는지 검사한다.
    - 웹 서버 : 패킷이 물리적 웹 서버에 도착하면, 웹 서버의 프로토콜 스택이 패킷을 추출하여 메시지를 복원하고, 웹 서버 애플리케이션에 넘긴다. 애플리케이션은 요청에 대한 응답 데이터를 넣어 클라이언트로 회송한다. 온 방식 그대로 전송되게 된다.

9. HTTP/HTTPS 차이
    - HTTP + SSL = HTTPS
    - HTTP는 평문 통신이다. TCP/IP 특성상 도청이 가능하며, 통신 상대를 확인하지 않기 때문에 위장이 가능하다. 가령 나는 IP가 A인 사람한테 보내고 싶은데, 악의적인 해커가 내가 IP A요 하고 말해도 검증할 방법이 없다는 것. 또한 완전성을 증명할 수 없기 때문에 변조가 가능하다. 보안 방법은 통신 자체를 암호화(SSL, TLS)하거나, 콘텐츠를 자체를(HTTP 메시지 컨텐츠를) 암호화 하는 것이다. 도청이 가능한 문제, 사용자를 확인할 수 없다는 문제, 정확성을 보장할 수 없다는 문제를 모두 해결할 방안으로 나온 것이 HTTPS이다.
    - HTTPS는 새로운 프로토콜이 아닌, HTTP에서 SSL 개념을 더한 프로토콜이다. 기존 HTTP는 TCP와 직접 통신했지만, HTTPS는 HTTP와 TCP 사이에 SSL, TLS가 끼워져 있는 것이다. HTTP는 SSL과 통신하고, SSL은 TCP와 통신하게 된다.
    - SSH Hand Shake 과정(TCP 3-way hand shake 이후)
        * Client Hello: 클라이언트가 서버에 연결을 시도하며 전송하는 패킷, 자신이 사용 가능한 Cipher Suite목록, Session ID, SSL Protocol Version, Random Byte 등을 전송. Cipher Suite는 SSL Protocol Version, 인증서 검정, 데이터 암호화 프로토콜, Hash 방식등의 데이터를 담고있어, 선택된 Cipher Suite의 알고리즘에 따라 데이터를 암호화
        * Server Hello: Client가 보내온 ClientHello Packet을 받아 Cipher Suite중 하나를 선택해 클라이언트에 알리면서, 자신의 SSL Protocol Version등도 같이 보냄
        * Certificate: Server가 자신의 SSL 인증서를 Client에 전달, 인증서 내부에는 Server가 발행한 공개키가 들어있음. Client는 Server가 보낸 CA(Certificate Authority, 인증기관)의 개인키로 암호화된 SSL인증서를, CA의 공개키로 복호화(인증서 검증)
        * Server Key Exchange/Server Hello Done: Server의 공개키가 SSL인증서 내부에 없는경우 Server가 직접 전달하는것. 공개키가 SSL인증서 내부에 있을경우 Server Key Excahge는 생략
        * Client Key Exchange: 대칭키를 Client가 생성해서 SSL인증서 내부에서 추출한 Server의 공개키를 이용해 암호화 한 후 Server에게 전달
        * Change Cipher Spec / Finished: Client, Server모두가 서로에게 보내는 Packet으로 교환할 정보를 모두 교환한 뒤 통신할 준비가 되었음을 알리는 패킷. 이후 Finished 패킷을 보내 SSL Handshake 종료

10. TCP/UDP 등 로우레벨 통신 지식
    - TCP 3-way hand shake
        * TCP/IP 프로토콜을 이용해서 통신하는 프로그램이, 데이터를 전송하기 전에 먼저 정확한 전송을 보장하기 위해 상대방과 사전에 세션을 수립
        * 클라이언트에서 서버로 접속을 요청하는 SYN패킷을 보냄. 클라이언트는 SYN을 보내고 SYN/ACK 응답을 기다리는 SYN_SENT 상태가 됨
        * 서버는 SYN 요청을 받고, 클라이언트에게 요청을 수락한다는 ACK와 SYN 플래그가 설정된 패킷을 발송하고 다시 클라이언트가 ACK로 응답하기를 기다리는 SYN_RECEIVED 상태가 됨
        * 다시 클라이언트는 서버에게 ACK 를 보내고, 이후 연결이 이뤄져 데이터가 오가게되고 서버의 상태는 ESTABLISHED가 된다

    - TCP 4-way hand shake
        * 3-way hand shake가 연결을 수립하기 위한것이였다면, 4-way hand shake는 세션을 종료하기 위해 수행
        * 클라이언트가 연결을 종료하겟다는 FIN 플래그 전송
        * 서버는 확인 메시지인 ACK를 보내고, 자신의 통신이 끝날때까지 기다리게 되는데 이 상태가 TIME_WAIT
        * 서버의 통신이 끝났으면 연결이 종료되었다고 클라이언트에게 FIN 플래그 전송
        * 클라이언트는 확인했다는 ACK를 다시 클라이언트로 보내고 연결 종료
        * 서버에서 FIN을 전송하기전 전송한 패킷이 Routing지연이나 패킷 유실로 인한 재전송 등의 이유로 FIN보다 늦게 도착할 경우, 이 패킷은 Drop되고 유실될것이다. 클라이언트에서는 이를 방지하기 위해 서버로부터 FIN을 수신하더라도 일정 시간(디폴트 240초) 동안 세션을 남겨놓고 잉여 패킷을 기다리는데, 이 상태가 TIME_WAIT이다

    - TCP는 흐름제어, 오류제어를 통한 연결 지향성, 순서 중요함, 오류시 재전송. 전이중과 점대점(각 연결이 정확히 2개의 종단점을 가지고 있음) 방식.
    - UDP는 비연결형 프로토콜, 상대방이 받든지 말든지 그냥 보낸다. 손상된 세그먼트에 대해 재전송하지 않는다. 만약 클라이언트 timeout이 발생하면 다시 보내면 그만이다.

11. CORS란?
    - Cross Origin Resource Sharing 약자. 말 그대로 다른 도메인간의 자원 공유를 의미한다. 본래 대부분의 브라우저는 타 도메인 간 요청을 Same-Origin-Policy에 의해 차단한다. 이런 설정을 우회하기 위해 여러 방법이 있었지만, HTML5가 등장하면서 CORS가 등장했다. CORS는 헤더를 통하여 Cross-Domain간 사용가능한 자원을 헤더를 통하여 알려준다.

12. 배포 전략
    - Rolling: 서비스중인 서버를 한대씩 구버전에서 신버전으로 교체. 서비스중인 서버 한대를 제외 시키고 그자리에 신버전 서버를 추가. 트래픽을 점진적으로 변경. 서버수의 제약이 있을때 유용하나, 배포중 인스턴스의 수가 감소하므로, 처리 용량을 미리 고려 해야함
    - Blue/Green: 구버전에서 새버전으로 일제히 전환하는 전략. 구버전의 서버와 신버전의 서버를 동시에 나란히 구성하고, 배포시점이 되면 트래픽을 일제히 전환. 한번에 하나의 버전만 프로덕션 되므로, 버전 관리 문제를 방지 할 수 있고, 빠른 롤백이 가능. 운영 환경에 영향을 주지 않고 실제 서비스환경으로 새버전 테스트 가능. 단 시스템 자원이 2배로 필요하고, 전체 플랫폼에 대한 테스트가 이뤄져야 한다
    - Canary: 구버전과 새버전의 서버들을 구성하고 일부 트래픽을 새버전으로 분산하여 오류 여부를 판단. 분산 후 결과에 따라 새 버전이 운영 환경을 대체할수도 있고, 다시 구버전으로 돌아갈수도있다

13. 모놀리식 아키텍처와 MSA
    - Monolithic Architecture: 모듈별로 개발을 한 후, 개발이 완료된 애플리케이션을 하나의 결과물로 패키징하여 배포되는 형태
        * 개발, 빌드, 배포, 테스트가 용이함
        * CI/CD가 어렵고, 모든 모듈이 하나의 프로세스에서 돌아가기 떄문에, 하나의 모듈이 수정되어 서버를 내렸다 올릴경우 다른 모듈들도 그동안 작동 불가능한 상태가 됨

    - Mirchroservice Archetecture: 애플리케이션을 느슨히 결합된 서비스의 모임으로 구조화하는 서비스 지향 아키텍처(SOA) 스타일의 일종인 소프트웨어 개발 기법. 이로 인해 쉽게 교체 될 수 있고, 독립적으로 개발되고 전개될 수 있는 작은 어플리케이션이 마이크로서비스
        * 마이크로서비스의 핵심은 한가지만 아주 잘 처리하자 이며, 이로 인해 큰 문제들을 작은 문제로 나누어 해결, 작게 나뉘어진 서비스가 서로에게 영향을 미치지 않고 독립적으로 역할을 수행
        * 각각의 서비스가 오직 자신과만 상호작용 하는 DB를 가지기 때문에, 서비스마다 DB종류도 다르게 가질수있지만, 각 서비스별 데이터 중복이 일어날 수있고, 한쪽의 데이터만 업데이트 될 수도 있다
    
    - 모놀리식 아키텍처는 어플리케이션 확장시 운영에 관한 업무량이 증가하며, 새로운 기능 추가에 따른 라인수와 복잡도 증가, 불가피하게 어플리케이션을 수직/수평으로 확장해야한다
    - 모놀리식 아키텍처는 특정 서비스에만 트래픽이 몰려서 로드밸런서를 두어 확장해도, 모든 모듈이 하나의 어플리케이션으로 배포되기 때문에 어플리케이션 사본을 운영하는 서버를 두어 수평 확장해야 한다
        * 이렇게 확장할경우 기존 코드에 대해 무결성을 확인하기 위해 많은 테스트를 거쳐야 하며, 기술적 부채가 늘어난다. 그래서 이러한 형태가 Monolithic(단단히 하나로 짜여진)이다
    
    - 마이크로서비스 아키텍처는 작은 서비스 단위로 나누어 배포하기 떄문에 배포가 어렵고, 서비스간 통신 방식이 필요하며, 서비스를 나눠서 데이터간 중복이 있을 수 있고 정합성을 보장하기 어렵다

14. 스케일업, 스케일아웃
    - 스케일아웃: 여러대의 서버로 나누어 일을 처리하는것. 로드밸런서 필요
    - 스케일업: 서버가 더 빠르게 동작하기위해 서버의 하드웨어 성능을 올림

15. Spring에서의 예외 처리 전략
    - 통일된 Error Response객체를 가져야함. 그렇지 않으면 클라이언트에서 예외처리를 항상 같은 로직으로 처리하기가 어려움
    - ```@ControllerAdvice```로 모든 예외를 핸들링(예외 핸들 하면서 Response Body 다룰거면 ```@RestControllerAdvice```)
    - ```@ControllerAdvice``` 클래스에서 ```@ExceptionHandler```어노테이션으로 처리할 Exception을 지정해서 적절하게 처리
    - Error Code를 Enum으로 정의해 한곳에서 관리
    - 요구사항에 맞지 않는 요청이 들어온경우, Exception을 발생시켜 로직을 종료 해야함. 이것이 Business Exception
    - try-catch는 최대한 지양하며, 사용하게 될 경우 더욱 구체적인 Exception을 발생시켜라

16. OSI 7 Layer
    - 1 물리계층: 물리 매체를 통해 Bit흐름을 전송, 물리적 장치와 인터페이스가 전송을 위해 필요한 기능과 처리절차 규정
    - 2 데이터링크: 노드와 노드 사이의 데이터 전달, 단순 bit를 전송하는 물리층에 신뢰성을 더하기 위한 흐름제어및 오류제어기능, LLC와 MAC 2개의 서브Layer
    - 3 네트워크: 송신측에서 최종 목적지까지 데이터를 전달, 송수신측의 논리주소 지정및 최종목적지에 도달하도록 경로를 배정하는 라우팅기능, 데이터링크의 물리주소는 패킷이 시스템으로 이동할때마다 변경되지만, 네트워크 주소는 목적지까지 변하지 않음
    - 4 전송: 네트워크 계층에서 패킷을 종단까지 전달한다면(네트워크 주소), 전송층은 종단 내에서 최종 수신 프로세스로의 전달(포트 주소)을 담당, 분할/재조립, 연결/흐름제어, 오류제어
    - 5 세션: 통신하는 프로세스 사이의 대화제어 및 동기화 담당
    - 6 표현: 데이터의 변환, 압축, 암호화를 담당
    - 7 응용: 사용자에게 서비스 제공 역할, SMTP, FTP, HTTP등 사용자가 원하는 최종목표에 해당

17. Proxy
    - 프록시는 보안등의 이유로 직접 통신할수 없는 서버와 서버 사이의 중개자 역할
    - Forward 프록시: 프록시를 클라이언트와 인터넷 사이에 위치시킴. 클라이언트가 요청한 리소스를 원격에서 가져와서 클라이언트에 forward 해주는 역할. 그래서 보통 캐슁기능이 있고, 자주 사용하는 컨텐츠라면 월등한 성능 향상을 가져올수 있음
    - Reverse 프록시: 프록시를 인터넷과 내부서버 사이에 위치시킴. 리버스 프록시가 요청을 받아서 내부 서버에서 데이터를 받아 데이터를 클라이언트에 전달. 내부서버가 직접 제공하는것 대신 보안을 확보하기 위해 사용. DMZ라고 하는 내부/외부 네트워크 모두 접근할 수 있는 공간에 리버스 프록시를 위치시키고, 실제 서비스는 내부망에 위치하도록 하여서 보안 확보. 일반적으로 WEB(Apache, nginx) - WAS(Tomcat) 분리형태에서, WEB이 리버스프록시가 된다. 리버스 프록시에 인증서 두어서 인증

18. 서버가 1000개 있는데 1분내로 싹다 릴리즈 해야 한다면?
    - 서버 배포 전략을 잘 사용 해야 할것 같다
    - 시간이 문제되는 경우라면 블루/그린이 적합하지 않을까
19. C10K
    - 하나의 웹서버에 10000개의 클라이언트 접속을 동시에 다루려면?
    - 대표적인 해결 방법이 Nginx
    - 이벤트 기반의 비동기 처리
    - 이벤트 루프가 계속 돌면서 작업을 요청받고, 요청받은 작업을 콜백에 쌓음
    - 콜백에서는 순서대로 작업을 실행하는 대신 I/O 작업이 종료되면 이벤트를 발생시키는데, 이벤트는 해당 프로세스의 이벤트 큐에 등록되고, 프로세스가 이 큐에 새로 등록된 이벤트를 감지하여 작업 실행

20. HTTP란? HTTP1/2 차이
    - HTTP(Hyper Text Transfer Protocol)이란 서버/클라이언트 모델을 따라 데이터를 주고 받기 위한 프로토콜. 애플리케이션 레벨의 프로토콜로 TCP/IP 위에서 동작하며, 상태를 가지고있지 않는 Stateless 프로토콜로 Method, Path, Version, Header, Body로 구성
    - HTTP 1.x
        + HTTP 헤더 + 바디로 구성
        + 헤더에는 URI, Request Method 등 여러 헤더 정보가 포함
        + 사람이 읽을수있는 문자열이 그대로 전송
        + TCP 커넥션을 이용하므로 3-way-handshake를 사용하게 되어있음
        + HOL(Head of Line) Blocking 특정 응답 지연 문제 - 클라이언트 리퀘스트 순서와 서버의 응답 순서가 동기화 되기 때문
        + 헤더가 큼 - 쿠키등 다양한 메타정보가 저장 되어 있기 때문에
    - HTTP 2.0
        + Body가 binary framing layer라고 하는 공간에 이진 데이터로 되어서 전송. HTTP Reqeus Method, 헤더등은 여전히 문자열이지만 바디가 변경됨
        + 멀티플렉싱 - 하나의 TCP연결에 여러 스트림을 사용해서, 여러 요청/응답을 병렬로 처리
        + 스트림 우선순위 지정 - 1개의 TCP에 여러 스트림을 사용할수있게 되므로, 각각의 스트림에 우선순위 부여 가능
        + 헤더 압축 - HPACK 압축을 통해서 헤더를 압축해서 보냄 
        + Server Push - 클라이언트에게 필요한 데이터가 있을때, 직접 요청하기 전에 서버가 미리 데이터를 전송하여 받아볼수 있게 함
    - HTTP 3
        + UDP

21. TCP/IP 프로토콜 4계층
    - OSI와 달리 실무적으로 적용 가능한 모델
    - L1 네트워크 연결 계층
        * 데이터 단위: 프레임
        * 전송 주소: MAC
        * 물리적으로 데이터가 네트워크를 통해 어떻게 전송되는지를 정의(논리 주소가 아닌 물리주소 - MAC)
        * 에러검출 및 패킷의 프레임화 담당
        * 프레임 단위의 데이터 구성 - 데이터 전송 전에 패킷헤더에 MAC주소와 오류검출부 첨부
        * Ethernet, PPP, Token Ring
    - L2 인터넷 계층
        * 데이터 단: 패킷
        * 전송 주소: IP
        * 네트워크상 최종 목적지까지 정확하게 연결되도록 연결성을 제공
        * 단말을 구분하기 위해 논리적 주소인 IP를 할당
        * 출발지와 목적지의 논리적 주소가 담겨있는 IP datagram이라는 패킷으로 데이터 변경
        * 라우팅 기능을 처리 - 경로 설정
        * 최종 목적지까지 정확하게 연결 되도록 연결성 제공
        * 패킷 단위의 데이터 구성 - 세그먼트를 목적지까지 전송하기 위해 시작주소와 목적지의 논리적 주소를 붙인 단위
        * IP, ARP, ICMP, RARP
    - L3 전송 계층
        * 데이터 단위: 세그먼트
        * 전송 주소: 포트
        * 통신 노드간의 연결 제어 및 자료 송수신을 담당
        * 어플리케이션 계층의 세션과 데이터그램 통신 서비스 제공
        * 세그먼트 단위의 데이터 구성 - 실질적 데이터 전송을 위해 데이터를 일정 크기로 나눈것, 발신, 수신, 포트주소, 오류검출코드가 추가됨
        * TCP, UDP, RTP 등
    - L4 응용 계층
        * 데이터 단위: 데이터/메시지
        * 사용자와 가장 가까운 계층으로 사용자가 소프트웨어와 소통할 수 있게 해줌
        * 응용프로그램들이 데이터를 교환하기 위해 사용되는 프로토콜
        * 사용자 응용프로그램 인터페이스를 담당
        * 파일전송, 이메일, FTP, HTTP, SSH, DNS, SMTP 등

22. TCP / UDP
    - TCP
        * 연결 지향형 전송 규약
        * 흐름 중심 프로토콜, 통신을 주고 받는것을 중요시함
        * 중간에 패킷이 손실되는 경우 재전송을 통해 신뢰성을 보장
        * 대부분의 통신 및 파일 이나 데이터 전송시 사용
    - UDP
        * 비 연결 지향형 전송 규약
        * 데이터 중심의 프로토콜, 주고받는 통신보다 데이터를 일방적으로 보내는것을 중시함
        * P2P, 스트리밍, 전화등에 사용

23. Spring WebFlux
    - Spring5에 처음으로 등장
    - 기존의 Spring MVC는 HTTP 요청들을 큐에 넣어두고, 멀티 쓰레드 기반으로 동작. 응답성이 상대적으로 떨어지는 문제 발생
    - 이 문제를 해결하기 위해 비동기 데이터 스트림으로 Non-Blocking 애플리케이션을 개발하기위한 필요성이 생김
    - 그래서 Reactive Stream(논블로킹 백프레셔를 이용한 비동기 데이터 처리 표준)의 구현체인 Project Reactor 의 웹 스트리밍을 담당하는 Webflux가 등장
    - Servlet을 그대로 사용할수도 있지만, Netty를 사용하는게 권장

24. CDN(Content Delivery Network)
    - 물리적으로 떨어져잇는 사용자에게 컨텐츠를 더 빠르게 제공하기위해 고안된 기술
    - 서버를 분산해 캐싱시켜두고, 컨텐츠 요청이 발생하면 사용자와 가장 가까운 서버로 매핑시켜 요청된 파일의 캐싱된 버전으로 요청 처리
    - 서버가 파일을 찾는데 실패한 경우 CDN플랫폼의 다른 서버에서 콘텐츠를 찾은다음에 응답 전송

25. 서버에서 DISK I/O가 많아서 병목이 발생한다 어떻게 해야 좋을까?
    - 일단 file system 의 마운트 옵션부터 바꾸는게 좋을듯? 타임스탬프(atime / access time)이 영향을 많이주니 noatime 적용
    - 디스크 캐싱: 자주 접근한 디스크 내용을 저장하고, 접근시 저장된곳부터 찾는 방식
    - 램디스크: 메모리의 일부분을 고정적으로 할당하여 디스크인척 사용하는 방법

26. 웹의 3계층
    - 프레젠테이션 로직(클라이언트, 사용자 인터페이스), 비즈니스 로직, 데이버베이스 로직을 각각 다른 플랫폼 상에서 구현한것. 각 계층은 물리적으로 독립적이며, 다른 계층에 의존하지 않음
    - 프레젠테이션 계층
        * 응용프로그램의 최상위에 위치해, 서로 다른 층에 있는 데이터등과 커뮤니케이션을 함
        * 사용자 인터페이스를 지원, GUI, Frontend
        * 비즈니스 로직이나 데이터 관리 코드를 포함하면 안됨. 주로 웹서버를 뜻함
    - 어플리케이션 계층
        * 정보 처리의 규칙을 갖고 있음
        * 미들웨어 또는 백엔드, 주로 어플리케이션 서버를 뜻함
    - 데이터 계층
        * 데이터베이스와 그것에 엑세스 해서 쓰거나 관리하는 프로그램
        * DB 또는 파일시스템을 접근 관리

27. React, Vue
    - React
        * Template 구조를 사용하지 않고, 개발자가 JSX를 사용하여 자바 스크립트에서 DOM을 생성
        * 큰 규모에 좋고, 테스팅이 수월
        * Web/Native 앱 개발에 모두 사용 가능
    - Vue
        * Template와 Render Function을 모두 사용할수있음
        * 간편한 Syntax와 프로젝트 설정
        * 빠른 렌더링과 더 작은 용량
    - 공통점
        * Virtual DOM으로 빠른 랜더링
        * 경량 라이브러리
        * 리액티브 컴포넌트(비동기 스트림 처리)

28. DOM
    - HTML 문서에 대한 인터페이스. 기본적으로 여러 프로그램들이 이 페이지의 곤텐츠 및 구조 그리고 스타일을 조작 할 수 있도록 API 제공
    - DOM은 HTML 요소들의 구조화 된 표현, 뷰 포트에 무엇을 렌더링 할지 결정하기 위해 사용, DOM은 페이지의 콘텐츠 및 구조, 그리고 스타일이 JS에 의해 수정되기 위해 사용
    - 항상 유용한 HTML 형식, JS에 의해 수정될 수 있는 동적 모델, 가상 요소를 포함하지 않고, 보이지 않는 요소를 포함함

29. Spring Batch
    - Batch: 일괄처리, 즉 단발성으로 대용량의 데이터를 처리하는 어플리케이션이 배치 어플리케이션
    - Batch 어플리케이션의 조건
        * 대용량 데이터 - 대량의 데이터를 가져오거나, 전달하거나, 계산하는등의 처리를 할수 있어야 함
        * 자동화 - 배치 어플리케이션은 심각한 문제 해결을 제외하면 사용자의 개입 없이 실행 되어야 함
        * 견고성 - 잘못된 데이터들을 충돌/중단 없이 처리할 수 있어야 함
        * 신뢰성 - 배치 어플리케이션은 무엇이 잘못 되었는지 추적 가능해야 함(로깅, 알림 등)
        * 성능 - 지정된 시간 안에 처리를 완료하거나, 동시에 실행되는 다른 어플리케이션을 방해 하면 안됨
    - Spring Batch는 Spring의 특성을 그대로 가져와서 DI, AOP등을 그대로 사용 가능

30. 클라이언트 근처의 CDN은 어떻게 파악해서 거기로 보내줄까?
    - Global Server Load Balancing
        * 주기적으로 등록된 호스트에 대해서 health check를 함으로, health check가 실패한 서버는 응답에서 제외. 사용자로 하여금 서비스 실패 확률을 낮춤
        * 주기적으로 성능을 측정하고 결과를 저장하기 때문에, DNS요청이 오면 지리적으로 가까운 서버를 반환하거나 네트워크 거리가 가까운 서버를 반환 
        * 서비스 로직
            + 사용자가 www.example.com에 접속하기 위해서 자신의 local DNS서버로 dns query를 보내고, local DNS는 Root DNS등을 거쳐서 GSLB로 보냄
            + GLSB는 DNS proxy로 동작하여 접속하기 위한 www.example.com의 DNS로 DNS쿼리를 보냄
            + www.example.com의 DNS서버는 www.example.com에 대한 IP주소(SLB의 VIP)로 등록되어있는 IP들을 GLSB로 반환
            + GLSB는 나름의 정책(뭐 가장 가까운 서버 라던지, 가장 응답이 빠른 서버 등)으로 최적을 결정
            + GLSB에 의해 결정된 IP가 Local DNS에게 전달되고, Local DNS는 그 값을 사용자에게 전달
            + 사용자는 www.example.com의 주소를 전달받은 목적지로 설정하고 요청을 보내면, 그걸 받은 SLB가 또 최종 서버를 결정해서 요청을 전달
    - 물리적으로 가장 가깝거나 여유 트래픽이 남는 곳으로 접속을 유도
    - 서버의 상태를 모니터링(주기적으로 Health Check 수행)하고 실패한 서버의 IP는 응답에서 제외
    - 서버의 로드를 모니터링 하기 때문에 로드가 가장 적은 IP를 반환하는 형식의 로드밸런싱도 가능
    - 각 지역별로 서버에 대한 레이턴시를 가지고 있기 때문에 유저가 접근하면, 유저의 지역으로부터 가장 가까운(레이턴시가 가장 적은)서버로 연결
    - 유저의 지역 정보를 기반으로 해당 지역을 서비스하는 서버로 연결도 가능

31. 클라이언트에서 접속하면 서버는 로케일은 어떻게 파악할까?
    - IP
    - 라우터 사이를 홉(점프)하면서 라우터의 정보를 받아오는 방법도 있다던데... 잘 모름

32. 로드밸런서 L4, L7 차이
    - L4
        * TCP/UDP 포트 정보를 바탕으로 로드밸런싱
        * 데이터 안을 들여다보지 않고 패킷 레벨에서만 로드를 분산하기때문에 속도가 빠르고 효율이 높음
        * 데이터의 내용을 복호화 할 필요가 없어서 안전
        * 패킷의 내용을 살펴볼수없기 때문에 섬세한 라우팅이 불가능
        * 사용자의 IP가 수시로 바뀌는 환경이라면 연속적으로 서비스 제공하기가 어려움
    
    - L7
        * TCP/UDP 정보는 물론 HTTP의 URI, FTP의 파일명, 쿠키정보등을 바탕으로 로드밸런싱
        * 상위계층에서 로드를 분산하기 때문에 더 섬세한 라우팅 가능
        * 캐싱기능 제공
        * 비정상적인 트래픽을 사전에 감지할수있어서 서비스의 안정성이 높음
        * 패킷의 내용을 복호화 하기에 더 높은 비용을 지불해야함

33. 로드밸런서 로드밸런싱 방법 종류
    - Round Robin: 요청을 순서대로 각 서버에 분산
    - IP Hash: 클라이언트의 IP주소를 특정 서버로 매핑. 사용자가 항상 같은 서버로 연결되는것을 보장
    - Least Connection: 서버에 연결되있는 커넥션의 개수만 가지고 단독 비교하여서 가장 적은곳에 연결
    - Weighted Least Connections: 서버에 부여된 가중치와 커넥션 개수를 같이 고려해서 연결
    - Fastest Response Time: 가장 빨리 응답하는 서버에 연결
    - Adaptive: Open 또는 Pending 커넥션을 적게 가지고 있는 서버로 네트웍 커넥션 방향을 지정

34. Spring 국제화
    - Spring IoC 컨테이너가 가지고 있는 MessageSource 를 통해 국제화(i18n)과 관련된 기능 처리 가능
    - Resource 디렉터리 밑에 messages_xx 이런 형식으로 작성하면 messages리소스 번들로 묶임
    - Spring Boot의 경우엔 자동으로 ResourceBundleMessageSource이 빈으로 등록되고, 이 빈이 messages리소스 번들을 메시지 소스로 읽어옴 
    - HTTP 요청의 Accept-Languag 헤더, 세션의 속성, 쿠키에 있는 language등 다양한 방법으로 확인해서 해당 언어로 지원 

35. Nginx를 이용한 무중단 배포
    - 사용자는 서비스 주소로 접속(Nginx의 주소)
    - Nginx는 사용자 요청을 받아 현재 연결된 서비스로 요청 전달
    - 연결되지 않은 다른 서비스에 배포
    - 배포후 정상적으로 두번째 서비스가 동작하는지 확인
    - 정상 동작 한다면 nginx reload해서 nginx를 2번과 연결

36. 세션이란?
    - 일정 시간동안 같은 클라이언트로부터 들어오는 일련의 요구를 하나의 상태로 보고, 그 상태를 일정하게 유지 시키는것
    - 웹 서버가 세션 아이디 파일을 만들어 서비스가 돌아가고있는 서버에 저장
    - HTTP Session 동작 순서
        * 클라이언트가 서버로 접속을 시도
        * 서버는 클라이언트의 request -header field인 cookie를 확인해 클라이언트가 해당 session-id를 보내왔는지 확인
        * 클라이언트로부터 발송된 session-id가 없다면 서버는 session-id를 생성에 클라이언트에게 resoponse-header field인 set-cookierkqtdmfh session-id를 발행
     
     - Session 저장 방식
        * In memory: 서버의 메모리에 Session을 생성, 서버 재시작시 세션 유지가 되지 않으며, 과다하게 메모리를 사용할수있단 문제가 있음
        * File Storage: 서버의 특정 디렉토리에 파일 형태로 Session 생성. 서버가 여러대일경우 한쪽 서버에 생성된 세션 파일을 다른 서버에서는 접근 못하니 문제 발생
        * Database Storage: DB에 저장

    - Spring Boot에서의 세션
        * ```@SessionAttributes```,```@ModelAttribute```,```@SessionAttribute```,```@SessionStatus```등을 사용해서 세션에 값을 저장하고 가져옴


37. Nginx 로드밸런싱
    - nginx의 컨피그를 수정해서 upstream 블락을 만들어 로드밸런싱할 서버를 정해줌
    - 디폴트 설정은 라운드로빈 방식, 이외에 커넥션이 가장 적은 서버를 할당하는 리스트커넥션, 클라이언트 ip를 해쉬한값을 기반으로 특정 서버에 주는 ip hash등이있음

38. 캐시서버 & Redis
    - 한번 읽어온 데이터를 임의의 공간에 저장하여 다음에 읽을땐 빠르게 결과값을 받도록 도와주는게 캐시
    - Redis
        * 키 - 벨류 기반의 인메모리 데이터 저장소. 키 - 벨류 기반이라 쿼리를 따로 만들 필요 없이 결과를 바로 가져올수 있으며, 인메모리라 빠르다
        * Redis Collection에는 Strings, Lists, Sets, Sorted Sets, Hashes 등이 있음
        * 캐시 데이터 저장 이외에도 인증 토큰 저장, Ranking Board,세션 클러스터링등 다양하게 쓰임
        * Redis는 기본적으로 Single Thread기 떄문에 초당 처리시간이 긴 명령어를 넣으면 그 뒤에건 밀림(짧은 Get/Set같은건 초당 10만개도 가능하다함)
        * 클러스터 구성도 가능하다고 함
        * 서버의 주 메모리에 상주하면서, 작업을 위해서 디스크까지 왕복해야한다는 단점이 사라짐
        * 기본으로 복제 아키텍처를 사용하며 비동기식 복제를 지원하므로 데이터가 여러 복제 서버에 복제 될 수 있음. 주 서버에 장애가 발생해도 여러 서버로 분산될 수 있으므로 읽기, 쓰기 성능이 더 좋고 빠른 복구가 가능함. 지속성을 위해 특정 시점 백업도 된다고 함
        * 캐싱, 채팅, 메시징, 세션 스토어 등등 다양한 방법으로 활용 가능
        * Spring 에서는 Spring Data Redis를 사용해서 ResidTemplate(String, List, Set 등을 기반으로 접근), RedisRepository(JPA처럼 객체 기반으로 접근) 2가지 접근 방식으로 Redis에 접근해사 사용 가능

39. Kafka
    - 카프카는 기본적으로 Publish-Subscribe 모델을 구현한 분산 메시징 시스템
    - Publish-Subscribe 모델은 데이터를 만들어내는 프로듀서(Producer, 생산자), 소비하는 컨슈머(Consumer, 소비자) 그리고 이 둘 사이에서 중재자 역할을 하는 브로커(Broker - 하나의 카프카 서버)로 구성된 느슨한 결합(Loosely Coupled)의 시스템
    - 여러 클라이언트가 많은 토픽을 사용하거나, 같은 토픽을 사용해도 카프카는 무리없이 많은 프로듀서의 메시지 처리 가능
    - 많은 컨슈머가 상호 간섭 없이 어떤 메시지 스트림도 읽을 수 있음
    - 지속해서 메시지를 보존할 수 있고, 컨슈머가 항상 실시간으로 읽지 않아도 되며 확장성이 좋음
    - Event(데이터를 주고 받는 단위), Producer(Kafka에 이벤트를 게시하는 클라이언트 어플리케이션), Topic(이벤트가 쓰이는곳, Producer가 여기에 이벤트를 게시하고 Consumer가 Topic으로부터 이벤트를 가져와서처리), Consumer(Topic을 구독하고 이벤트를처리)
    - Topic은 여러 Broker에 분산되어 저장되며, 이렇게 분산되 저장되있는 Topic을 Partition이라고 함. 어떤 이벤트가 Partition에 저장 될지는 이벤트의 Key에 의해 정해지며, 같은 키를 가지는 이벤트는 항상 같은 Partition에 저장됨. Kafka는 Topic의 Partition에 지정된 Consumer가 항상 정확히 동일한 순서로 Partition의 이벤트를 읽을것을 보장
    - Producer와 Consumer의 분리: Kafka의 Producer와 Consumer는 완전 별개로 동작. Producer는 Broker의 Topic에 메시지를 게시하기만 하면 되며, Consumer는 Broker의 특정 Topic에서 메시지를 가져와 처리 하기만 하면됨. 이로 인해서 높은 확장성이 제공됨. Producer 또는 Consumer를 필요에 의해 스케일 아웃 하에 용이한 구조
    - Kafka의 Consumer는 Pull 모델 기반: Broker가 Consumer에게 메시지를 전달하는게 아닌, Consumer가 필요할때 Broker로부터 메시지를 가져와 처리하는 형태. 다양한 Consumer의 처리 형태와 속도를 고려하지 않아도 됨(Consumer가 처리 가능할때에 메시지를 가져와 처리하기 때문), 불필요한 지연 없이 일괄처리를 통해 성능향상 도모 가능(Push 모델에는 더 많은 메시지를 한번에 처리하도록 하기 위해 Buffering을 할 수도 있지만 그런 경우에는 Consumer가 현재 메시지를 처리할수 있음에도 대기를 해야함. 그렇다고 전송 지연시간을 최소로 하면 한번에 하나의 메시지만 보내도록 하는것과 같아져서 매우 비효율. 하지만 Pull 모델의 경우는 마지막으로 처리된 메시지 이후의 메시지를 Consumer가 처리 가능한때에 모두 가져오기 때문에 이 문제를 해결)
    - 소비된 메시지 추적(Commit 과 Offset)
        * 메시지는 지정된 Topic에 전달되고, Topic은 다시 여러 Partition으로 나뉠 수 있음. 이러한 메시지의 상대적인 위치를 offset이라고 칭함
        * 메시징 시스템은 Broker에서 소비된 메시지에 대한 메타데이터를 유지, 메시지가 Consumer에게 전달되면 Broker는 이를 로컬에 기록하거나, 소비자의 승인을 기다림
        * Consumer의 poll()은 이전에 commit한 offset이 존재하면 해당 offset이후의 메시지를 읽어옴. 그 후 마지막 offset을 commit 함으로써, 다음 poll() 실행시 방금전 commit한 offset이후의 메시지를 읽어와 처리하게 됨
        * Broker가 메시지를 네트워크를 통해 Consumer에게 전달할 때마다 즉시 소비된것으로 기록하면, Consumer에서 메시지 처리를 실패할경우 해당 메시지가 손실됨
        * 그래서 Broker는 메시지가 소비되었음을 기록하기위해서 Consumer의 승인을 기다리지만, Consumer가 승인을 보내기전에 Broker가 실패했다고 판단하여 다시 메시지를 보내게되면 Consumer는 같은 메시지를 두번 처리하기 때문에, Consumer는 멱등성을 고려해야함. 즉, 같은 메시지를 여러번 받아서 여러번 처리하더라도 한번 처리한것과 같은 결과를 지니도록 설계 해야함

    - Consumer Group
        * Consumer Group은 하나의 Topic을 구독하는 여러 Consumer의 모음
        * 하나의 Topic을 처리하는 Consumer가 1개인것보다 여러개일때 가용성이 증가함
        * Consumer Group의 각 Consumer는 하나의 Topic의 각기 다른 Partition의 내용만을 처리할 수 있는데, 이를 통해서 메시지 처리 순서를 보장한다고함
        * 특정 Partition을 처리하던 Consumer가 처리 불가 상태가 된다면, 해당 Partition의 메시지를 처리할 수 없는 상태가 되어버리는데, 이때 Partition과 Consumer를 재조종하여 남은 Consumer Group 내의 Consumer들이 Partition을 적절하게 나누어 처리하게 됨. 또한 Consumer Group내에서 Offset정보를 공유하기 때문에 특정 Consumer가 처리 불가 상태가 되었을떄, Consumer가 처리한 마지막 Offset 이후부터 처리를 이어서 할 수 있다. 이것을 Reblance라고 한다
        * 따라서 Consumer가 확장되면 Partition도 같이 늘려줘야함

    - 메시지 전달 컨셉
        * At most once: 최대 한번, 메시지가 손실 될 수 있지만, 재전달은 하지 않음
        * At least once: 메시지가 손실되지 않지만, 재전달이 일어남
        * Excatly once: 메시지는 정확히 한번 전달됨

    - Kafka Connect
        * 데이터 소스와 Kafka를 연결해주는 매개체, Kafka Connect에는 Connector를 이용해서 데이터 소스와 연결
        * 즉 Kafka Connector가 Producer와 Consumer의 역할을 함. Producer 역할을 하는 Kafka Connector가 Source Connector라고 하고, Consumer 역할을 하는 Kafka Connector를 Sink COnnector 라고 함
        * Kafka Connector가 만들어내는 메시지는 Key와 Value로 구성되는데 Key와 Value 모두 Schema와 Payload로 구성됨. Key에는 PK와 같이 데이터를 식별할수있는 정보가 들어있고, value에는 데이터의 전체값이 들어있음. Payload에는 데이터 값이 저장되며 이 데이터 값의 타입이 Schema에 명시 되어있음
        * 동일한 메시지가 계속 들어오면 Schema가 중복되어 불필요하게 데이터 용량을 사용하므로 Schema Registry를 활용함. Schema Registry에 Schema를 따로 저장하여 Schema 대신 Schema Registry의 Schema 번호를 명시하여 메시지 크기를 줄임

    - Dead Letter
        * 메시지를 어떠한 이유로 처리할수 없는 경우가 발생할 수있음. deserialize할수 없는 경우나 데이터가 예상과 다른 경우 등이 있다고 함
        * Kaka Connect에는 이 Dead Letter를 처리하는 여러 방법이 있음
        * 단순히 데드레터를 무시하는 방법, 데드레터 큐를 사용해서 데드레터를 따로 관리하는 방법 등
        * 데드레터 큐에서 새로운 Kafka connect로 다시 sink connector로 보내는 방법도 있고 다양한듯
        * 일단 데드레터큐를 모니터링 하는게 좋을듯, JMX를 많이 사용하나봄

40. ElasticSearch
    - 오픈소스 실시간 분산 검색 엔진
    - JSON기반의 비정형 데이터 분산 검색 및 분석을 지원
    - 보통 3개 이상의 노드(ElasticSearch 서버)를 클러스터로 묶어 구성하며, 데이터를 샤드(분산하여 저장)로 저장시 클러스터내 다른 호스트에 복제본(레플리카)를 저장하기에 하나의 노드가 죽거나 샤드가 깨져도 복제되있는 다른 샤드를 활용해 데이터의 안정성 확보가 가능
    - 데이터의 분산과 병렬처리가 가능 하기에 실시간 검색 및 분석을 할 수 있고, 노드를 수평적으로 확장 가능하게 설계 되있어 더 많은 용량이 필요하면 클러스터에 노드를 추가하면 됨

41. Spring Rest Docs
    - API를 자동으로 문서화 하게 도와주는 도구
    - Swagger와의 차이점
        * Swagger는 서비스 코드에 Swagger 관련 어노테이션이 추가되어야함(```@ApiOperation```, ```@ApiIgnore```)
        * 테스트는 용이하지만 Swagger만으로 연동시스템을 만들기엔 힘듬
        * Swagger에 비해 Rest Docs는 서비스 코드에 영향을 주진 않지만 적용하기가 조금 더 어렵다
        * 테스트 작성이 필수로 요구되며, 테스트에 성공 해야지만 문서로 만들어준다
    
    - Rest Docs를 적용하고 테스트를 수행하면 adoc 라는 AsciiDoc 스니펫이 생기는데, 이를 기반으로 html파일을 만들어주는것

42. 대용량 트래픽 서버
    - DNS를 이용한 로드밸런싱
        * 하나의 도메인 이름을 여러 IP주소로 반환한다면 이것만으로도 어느정도 부하분산은 가능
        * DNS가 캐시를 사용하기때문에 고르게 부하분산이 되지 않고, health check 기능으로 장애 여부를 판단해서 제거하는데까지 시간이 걸림
    - L4 로드밸런서를 통한 로드밸런싱
        * IP주소와 포트를 기반으로 로드밸런싱
        * Virtual IP 기반으로 로드밸런싱이 되기 때문에, 하나의 VIP에 연결된 서버의 수가 비슷해야하며, 해당 VIP에 연결된 서버중 몇대가 문제가 발생하면, 해당 VIP내 다른 서버로 부하가 몰림
    - 로드밸런서 모듈(for 대용량 세션 서버, Naver)
        * 다양한 분산 알고리즘을 가진 조회서버
        * 세션 서버를 관리하는 서버 매니저, 세션 서버 목록을 저장하기 위한 주키퍼, 세션 서버 정보를 저장하기 위한 Redis
        * 단말과 1:1 세션을 맺고있는 세션 서버
        * 클라이언트는 세션 서버 주소를 얻기위해 조회 서버에 접속, 접속 가능한 세션의 주소를 가져오며, 정상적으로 세션의 주소를 받는다면 해당 세션 서버로 연결
        * 세션 서버에는 주기적으로 세션 수를 서버 매니저에 알려주는 기능과, 서버 매니저의 L7 health check요청에 응답하는 기능이 필요. 서버 매니저가 일정시간 health check에 실패한다면 해당 서버를 목록에서 제거
        * 조회 서버는 lookup 프로토콜을 제공해서, 클라이언트가 요청할때 어떤 세션 서버에 접근해야 하는지 알려주며, 세션 서버가 배포등으로 인해 서버 목록이 변경된경우 서버 매니저로부터 새로운 서버 목록을 받아서 업데이트
        * 조회 서버는 다양한 부하분산 알고리즘을 통해서 운영중에 서버 매니저의 요청으로 부하 분산 알고리즘이 변경이 가능하게 하며, 클라이언트의 접속 정보를 확인해서(국가 코드 등) 어떤 세션 서버에 접속해야 하는지 알려줄수도 있음
        * 조회서버 자체를 비동기 네트워크를 활용해서 높은 TPS도 처리 가능하게 만듬
        * 서버 매니저는 주기적으로 세션 서버의 health check를 수행하고, 세션 서버 정보를 redis에 저장함으로 조회 서버가 서버 정보를 요청하면 자신의 데이터를 바탕으로 서버 정보를 전달
        * 성능이 필요한 데이터 저장소로 Redis, 분산 데이터의 동기화는 주키퍼, 단말의 높은 트래픽 처리는 Netty등을 사용한 솔루션
    - HAProxy
        * 오픈소스 소프트웨어 로드밸런서. 소프트웨어적으로 로드밸런싱 수행
        * reverse proxy 방식으로 동작. 첫 서버 응답시 쿠키에서 서버 정보를 담아서 전달하고, 이후 사용자 요청시 쿠키를 확인해 최초 요청 서버로 다시 보내줄수 있도록 함
        * VRRP가 지원됨(VRRP 는 여러 대의 라우터를 그룹으로 묶어 하나의 가상 IP 어드레스를 부여해 마스터로 지정된 라우터 장애시 VRRP 그룹 내의 백업 라우터가 마스터로 자동 전환되는 프로토콜입니다. 이에 따라 디폴트 라우터 장애로 인한 네트워크 서비스 중단을 막을 수 있음)
        * 따라서 같은 VIP를 공유하는 HAProxy중 하나가 다운되더라도 다른 HAProxy가 대신 Master가 되서 일함. 이런 HA(High Availablility)모드에서는 최초 접근시 쿠키에 바로 서버정보를 담지 않고, 서버에서 jseesionid가 전달될때 서버 정보를 합쳐서 전달한다고 함
        * 클라이언트에서 연결되는 부분은 일단 GSLB를 구성하고, VIP + L4의 구성으로 하드웨어 이중화를 하고, L4에서 서버 앞단에 HAProxy를 둠으로써 HAProxy가 더 확장될 수 있게하면 높은 고 가용성을 만들 수 있다
        * Global Server Load Balancing
        * 주기적으로 등록된 호스트에 대해서 health check를 함으로, health check가 실패한 서버는 응답에서 제외. 사용자로 하여금 서비스 실패 확률을 낮춤
        * 주기적으로 성능을 측정하고 결과를 저장하기 때문에, DNS요청이 오면 지리적으로 가까운 서버를 반환하거나 네트워크 거리가 가까운 서버를 반환 
        * 서비스 로직
            + 사용자가 www.example.com에 접속하기 위해서 자신의 local DNS서버로 dns query를 보내고, local DNS는 Root DNS등을 거쳐서 GSLB로 보냄
            + GLSB는 DNS proxy로 동작하여 접속하기 위한 www.example.com의 DNS로 DNS쿼리를 보냄
            + www.example.com의 DNS서버는 www.example.com에 대한 IP주소(SLB의 VIP)로 등록되어있는 IP들을 GLSB로 반환
            + GLSB는 나름의 정책(뭐 가장 가까운 서버 라던지, 가장 응답이 빠른 서버 등)으로 최적을 결정
            + GLSB에 의해 결정된 IP가 Local DNS에게 전달되고, Local DNS는 그 값을 사용자에게 전달
            + 사용자는 www.example.com의 주소를 전달받은 목적지로 설정하고 요청을 보내면, 그걸 받은 SLB가 또 최종 서버를 결정해서 요청을 전달
    - DBMS를 클러스터링
    - SPOF(Single Point of Failure,장애 발생시 서비스 전체를 마비시키는 병목지점) 제거
    - 캐시도 적극 활용해야 할것 같고, API 게이트 웨이(API 서버들에 대한 로드 밸런싱), 메세지 큐를 이용한 비동기 처리 등등 다양한 방법을 생각해볼 수 있을듯
    - 쿠버네티스도 그중 한 방법이 될수있을듯
    - 어쨋던 모니터링 시스템을 잘 구축해서 그 모니터링 시스템에서 이상 트래픽을 감지해서 자동으로 조치할 수 있게 하면 좋을듯
        * 모니터링 시스템은 Spring Boot Actuator 써서 구축하면 될듯, thread, gc, cpu load 등등 다양한 정보를 확인 가능

43. 확장성 있는 웹 아키텍처와 분산 시스템
    - 가용성, 성능, 신뢰성, 확장성, 관리성, 비용중 어느것에 중점을 두고 설계할것인지가 중요
    - 기능별로 서비스를 구성해서(SOA - Service Oriented Architecture) 시스템을 기능 단위로 분리, 각각이 독립적으로 확장 가능하게 함. 그래야 각각의 문제를 독립적으로 해결
    - 장애에 대처하기 위해 데이터와 서버를 이중화. 단일 고장점을 없애고 장애 발생 시에도 백업하게 할 수 있거나 시스템이 계속 동작할 수 있게 한다

# Docker
   
1. Dokcer 개념
    - 기존 가상머신의 문제점: 가상머신은 구성요소 프로세스 뿐만 아니라, 시스템 프로세스를 실행해야 하기 때문에 추가 컴퓨팅 리소스가 필요함
    - 컨테이너 기술: 가상머신과 비슷하게 여러개의 서비스를 서로 격리하지만 오버헤드가 훨씬 적음. 컨테이너는 호스트OS에서 실행하는 하나의 격리된 프로세스에 지나지 않기 때문에, 어플리케이션이 소비하는 리소스만 소비하고 추가 프로세스의 오버헤드는 없음
    - 컨테이너 기술의 한계: 가상머신이 자체 리눅스 커널을 실행해 완전한 격리를 하지만, 컨테이너는 모두 동일한 커널을 호출함으로 보안 위험이 발생 할 수도 있음. 또한 호스트의 리눅스 커널을 이용하기 때문에 특정 커널 버전이 필요한 경우는 안됨
    - 컨테이너 격리가 가능하게 하는 기술: 리눅스 네임스페이스(각 프로세스가 시스템에 대한 독립적인 뷰만 볼 수 있도록), 리눅스 컨트롤 그룹(cgroups, 프로세스가 사용할 수 있는 리소스 양을 제한)
    - 도커는 컨테이너를 여러 시스템에 쉽게 이식이 가능하게 하는 컨테이너 시스템. 어플리케이션을 패키징, 배포, 실행 하기 위한 플랫폼
    - 도커 이미지: 애플리케이션과 해당 환경을 패키지화 한것
    - 도커 레지스트리: 도커 이미지를 저장하고 다른 사람이나 컴퓨터간에 이미지를 쉽게 공유할 수 있는 저장소
    - 도커 컨테이너: 도커 기반 컨테이너 이미지에서 생성된 일반적인 리눅스 컨테이너
    - 도커 이미지 레이어: 모든 도커 이미지는 다른 이미지 위에 빌드되며, 두개의 다른 이미지는 기본 이미지로 동일한 부모 이미지를 사용할 수 있기 때문에, 다른 이미지에도 정확히 동일한 레이어가 포함 될 수 있음. 따라서 한번 전송한 이미지와 같은 레이어를 가지는 이미지는 다시 전송할 필요가 없어 배포에 효율적이고, 이미지 스토리지 공간을 줄이는데 도움이 됨


2. Docker 파일의 구조
    - FROM: 베이스 이미지를 지정하는 명령어
    - RUN: 이미지 상의 리눅스 커맨드를 실행하게 해주는 명령어
    - CMD: 이미지 명령을 지정하기 위해서 사용하는 명령어
    - EXPOSE: 컨테이너에서 공개할 포트를 정의
    - ENV: 환경 변수를 정의하기 위해 사용하는 명령어
    - ADD,COPY: 이미지 안에 파일을 복사 하고자 할떄 사용, CPOY는 단순 복사, 추후 압축 해제등 후처리가 필요 하다면 ADD
    - WORKDIR: 작업 위치를 지정할때 사용
    - ONBUILD: 이미지 빌드 이후에 실행되는 명령을 지정
    - ENTRYPOINT: 이미지 실행 명령을 다시 지정하기 위해 사용. 이미지는 한번 만들어지면 다시 수정할 수 없기 때문에 프로그램 작성하듯이 쉘 짜두고 엔트리포인트로 걸어서 사용 가능
    - VOLUME: 바인딩 하고자 하는 디렉토리를 정의할떄 사용하는 명령어
    - USER: 사용자를 지정하기 위해 사용하는 명령어

3. Docker Compose
    - 다중 컨테이너 어플리케이션을 정의하고 공유할 수 있도록 개발된 도구. 컨테이너 실행에 필요한 옵션을 적어둘 수 있고, 컨테이너간의 실행 순서나 의존성 관리도 가능
    - 파일을 통해 어플리케이션 스택을 정의하고 이를 공유 함으로써 다른 사용자가 프로젝트 참여에 쉽게 참가할 수 있도록 하게 해줌

4. Docker Compose 파일 구조
    - Version: 파일 규격 버전. 버전별로 지원하는 옵션이 다르기때문에 주의
    - Service: 이 항목 밑에 실행하려는 컨테이너들을 정의
    - 서비스 이름: 서비스의 이름을 정함
    - image: 서비스에서 실행할 도커 이미지
    - volumes: docker에서 지정하는 VOLUME 옵션과 같지만, 상대 경로를 지정할 수 있음
    - environment: docker에서 지정하는 ENV 옵션과 동일
    - port: port 개방. 호스트 os와 컨테이너의 포트를 바인딩 해줌. docker compose up 해야지만 작동, docker compose run 할꺼면 --service-ports 옵션 해줘야함
    - expose: 호스트 os에 포트를 공개하지 않고 컨테이너만 포트를 공개. 호스트 os와 직접 연결될 필요 없이 컨테이너 끼리 통신만이 필요한 경우에 사용 
    - command: docker에서 run과 동일한 역할

5. Docker Compose 주요 명령어
    - up: docker compose 파일의 내용에 따라 이미지를 빌드하고 서비스를 실행. 서비스를 띄울 네트워크를 설정하고, 필요한 볼륨을 생성하거나 연결하고, 필요한 이미지를 풀 하고, 필요한 이미지를 빌드하고, 서비스 의존성에 따라 서비스를 실행
    - ps: 현재 실행중인 각 서비스의 상태를 보여줌
    - stop, start: 서비스를 멈추거나, 멈춰있는 서비스 실행
    - down: 서비스를 지우며, 컨테이너와 네트워크를 삭제, 옵션에 따라 볼륨도 지움
    - exec: 실행중인 컨테이너에서 명령 실행
    - logs: 서비스의 로그 확인. 뒤에 서비스 이름 적으면 해당 서비스것만 볼수있음

# Kubernetes

1. 쿠버네티스란 
    - 컨테이너화된 애플리케이션을 쉽게 배포하고 관리할수있게 해주는 소프트웨어 시스템
    - 리눅스 컨테이너의 기능에 의존하므로, 애플리케이션 내부의 세부사항을 알 필요 없이, 각 호스트에 애플리케이션을 수동으로 배포하지 않고도 이기종 애플리케이션을 실행 가능 
    - 애플리케이션이 각 컨테이너에서 실행 되므로, 동일한 서버에서 실행되는 다른 애플리케이션에 영향을 미치지 않음

2. 쿠버네티스 핵심
    - 쿠버네티스 시스템은 마스터노드와 워커노드로 구성. 개발자가 애플리케이션 메니페스트를 마스터에 게시하면 쿠버네티스는 해당 애플리케이션을 워커노드 클러스터에 배포
    - 구성요소가 어떤 노드에 배포되는지 개발자나 시스템 관리자에겐 중요하지 않음
    - 애플리케이션 개발자가 특정 인프라 관련 서비스를 애플리케이션에 구현하지 않아도 됨(서비스 디스커버리, 스케일링, 로드밸런싱, 자가치유 등)
    - 쿠버네티스는 클러스터 어딘가에 컨테이너화된 애플리케이션을 실행하고 구성요소간에 서로를 찾는 방법을 제공하고 모든 어플리케이션을 계속 실행하게 함

3. 쿠버네티스 클러스터 아키텍처
    - 마스터 노드는 전체 쿠버네티스 시스템을 제어하고 관리하는 쿠버네티스 컨트롤 플레인을 실행
    - 워커노드는 실제 배포되는 컨테이너 애플리케이션을 실행
    - 컨트롤 플레인
        * Kube API Server: 다른 컨트롤플레인들에게 요청을 받아 워커노드에 있는 kubelet을 통해 워커노드를 제어, REST API를 통해서 상태 제어, 다른 컨트롤 플레인 구성요소와 통신
        * Controller Manager: 구성요소 복제본, 워커노드 추적, 노드 장애 처리등과 같은 클러스터단의 기능을 수행
        * 스케줄러: 요청받은 리소스를 어느 노드에 실행할지 정함
        * ETCD: 클러스터 구성을 지속적으로 저장하는 신뢰할 수있는 분산 데이터 저장소

    - 워커 노드
        * 컨테이너를 실행하는 도커, rkt등 컨테이너 런타임
        * kubelet: Kube API 서버와 통신하고 노드의 컨테이너를 관리
        * kube-proxy: 어플리케이션 구성요소간의 네트워크 트래픽을 로드밸런싱 하는 쿠버네티스 서비스 프록시

4. Helm
    - 쿠버네티스 클러스터에서 패키지를 관리하는것. npm과 비슷
    - chart: 헬름 패키지. 쿠버네티스 클러스터 내에서 어플리케이션, 도구, 서비스를 구동하는데 필요한 모든 리소스 정의가 들어 있음
    - repository: 차트를 모아서 저장하고 공유하는곳
    - release: 쿠버네티스 클러스터에서 구동되는 차트의 인스턴스. 일반적으로 하나의 차트는 동일한 클러스터 내에서 여러번 설치 될 수 있는데, 그 때마다 새 release가 생성되는것(서로 다른 release name이여야함)

5. Deployment, Ingress, Service, Pod
    - Pod: 쿠버네티스에서 생성하고 관리 할 수 있는 배포 가능한 가장 작은 컴퓨팅 단위. 하나 이상의 컨테이너 그룹
    - Deployment: Pod과 ReplicaSet에 대한 선언적 업데이트를 제공. 어플리케이션을 다운타임 없이 업데이트 가능하도록 도와주는 리소스
    - Service: Pod 집합에서 실행중인 어플리케이션을 네트워크 서비스로 노출하는 추상화 방법
    - Ingress: 클러스터내의 Service에 대한 외부 접근을 관리하는 API 오브젝트


