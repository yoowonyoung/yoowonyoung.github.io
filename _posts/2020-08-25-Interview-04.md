---
layout: post
title: "프로젝트 정리"
description: 기술면접 준비
date: 2020-08-25 23:29:00 +09:00
categories: Interview
---

# 카카오 for Business CI/CD 파이프라인 개선
- 주요 사용 기술
    * Spring Boot
    * Jenkins
        - CI 툴
        - Jenkins kubernetes플러그인으로 쿠버네티스 클러스터에 Pod으로 Agent를 생성하여 Pod의 컨테이너에서 Job을 수행
        - 클러스터에서 빌드 배포를 수행 하므로, 관리 대상을 클러스터 하나로 줄일 수 있으며, 컨테이너의 제원제한으로 효율적인 CI/CD 구축이 가능하며, 컨테이너의 이미지를 사용해 일관된 환경에서 빌드, 배포를 수행할 수 있음
    * Kubernetes
        - 컨테이너화된 애플리케이션을 자동으로 배포, 스케일링 및 관리를 해주는 오픈소스 도구
        - 자동화된 롤아웃, 롤백이 지원되며 Horizontal 스케일링 및 로드밸런싱 기능등이 있음
        - Kubernetes는 회사 지침으로 사용하게 되었지만, 어플리케이션 배포의 단순화, 어플리케이션 개발의 단순화, 상태 확인이 되며 자가치유가 가능 등 다양한 이점이 있음
    * Docker
        - 리눅스 컨테이너를 만들고 사용할수 있게 해주는 컨테이너화 기술
    * Helm
        - Kubernetes의 패키지 관리 도구
        - 차트라는 패키지를 저장소에서 찾아오거나 업로드 하고, 이를 릴리즈 라는 이름으로 Kubernetes 환경에 설치함
        - deployment, service, ingress 등의 리소스 설정을 묶어 패키지화 함
        - 차트로 한꺼번에 묶어서 관리하기에, 관리가 용이함
    * 구성
        - Kakao for Business 서비스는 카카오톡 채널을 통해 홈 / 포스트 / 메시지 등의 다양한 기능을 제공하고있는 서비스
        - 해당 서비스에는 API서버, Auth 서버, Front서버 등 다양한 서버가 존재. 그중 일단 API 서버부터 진행중
        - 젠킨스 파이프라인으로 구성해 연속되는 이벤트를 처리
        - Build trigger에 의해 빌드 시작, Jenkins Agent를 클러스터에서 할당받아 Launch
        - 할당받은 Jenkins Agent가 Github 에서 소스를 Pull 받아 gradle의 jib플러그인을 이용 docker image를 빌드
        - 빌드된 docker image를 사내 dockerhub인 d2hub로 push -> 여기 까지가 빌드 잡
        - Jenkins Agent가 helm install을 실행해서 사내 chart repository에서 chart를 받아 클러스터에 설치
        - chart에 명시되어있는 docker image를 d2hub에서 받아 deployment, service, ingress를 클러스터에 배포 -> 여기 까지가 배포잡

- 역할
    * 기존 Dev phase에 구성된 Kubernetes + Jenkins 를 바탕으로 Sandbox Phase로도 확장 

- 성과
    * 현재 진행중

- 개인적 성취
    * Kubernetes 환경에 Jenkins 를 이용한 CI / CD 파이프라인 구축 경험

- 서비스 소개
    * https://business.kakao.com/

# 멜론 레거시 개선
- 주요 사용 기술
    * Spring Boot
    * MyBatis
    * Oracle

- 역할
    * 멜론의 가사 관리 어드민을 현재 사용하고 있는 신규 어드민으로 재구성
    * 16년된 가사 관리 기능을 모던자바를 이용해 개선
    * 기존 JDBC를 그대로 사용하던부분을 MyBatis를 사용 하도록 개선
    * JSP로 구성된 View를 Thymeleaf로 개선

- 성과
    * 레거시 어드민 코드를 개편하여 신규 어드민으로 재 구성, 테스트 서버를 통해 확인중(조직 변경으로 인하여 인수인계함)

- 개인적 성취
    * 레거시 코드를 분석 및 트렌드에 맞게 개편하여서 효율적으로 동작하게끔 구성해본 경험

- 서비스 소개
    * 멜론에 곡이 등록되면 유저가 직접 가사 등록을 하거나, 잘못된 가사를 신고하는 기능

# 멜론 콘텐츠 개발 프로젝트
- 주요 사용 기술
    * Spring Boot
    * MyBatis
        + ORM이 아닌 SQL Mapper
        + 비즈니스 로직상 복잡한 쿼리가 많았고, 또한 매우 많은 테이블이 존재 하였기 때문에 이를 다 엔티티로 만들기엔 무리가 있었음(META용 DB 테이블반 162개). 그래서 필드 매핑까지만 되는 SQL Mapper를 사용하였음
    * Thymeleaf
        + Spring boot에서 지원하는 서버사이드 템플릿 엔진(템플릿 양식과 특정 데이터 모델에 따른 입력 자료를 결합하여 원하는 결과 문서를 출력하는 소프트웨어)
        + JSP와 달리 Servlet code로 변환되지 않고, 비즈니스로직과 분리되어서 View 구현에만 집중 가능
        + 따로 여기서 뭘 더 쓴건 아니고 Thymeleaf 에 JQuery로 Ajax 통신
        + UI템플릿들이 만들어진게 이미 있어서, 그걸 베이스로 최대한 활용 하면서 만듬

- 역할
    * REST API 설계 및 구현
    * Admin Page View 구성 및 구현

- 성과
    * 멜론 트랙제로 서비스의 추천 트랙 리스트 관리기능 구현
    * 관리자가 해당 기능을 사용할 수 있도록 Admin 페이지 구성
    * 추후 트랙제로 연속감상 기능 구현시에도 활용될 예정

- 개인적 성취
    * Thymeleaf, MyBatis등 기존에 사용하던 기술 스택이 아닌 새로운 기술 스택 사용에 대한 경험
    * 기획자, DBA 등 다른 분야의 사람들과 협업을 해본 경험

- 서비스 소개
    * 음악 창작자가 직접 음원을 등록하는 멜론 트랙제로 서비스
    * 해당 서비스 화면에 보여줄 추천 트랙 혹은 보이지 말아야할 추천 트랙들을 관리하는 기능을 구현

# 전사 개발 데이터 가시화 Dashboard

- 주요 사용 기술
    * Spring Boot: Spring이 제공하는 다양한 라이브러리를 빠르게 사용할 수 있도록
    * Docker
        + 도입 배경: 기존 서비스는 아주 고전적인 배포 방식을 사용 하고있었음( 서버에서 서비스 실행 ), 따라서 현재 버전에 문제가 발생해서 Roleback을 해야한다던가 할때에 불편함이 많았음. 이를 수월하게 관리하고자 각 버전별 Docker image을 배포해서 관리 하기 위해서. 또한 서버 환경이 변경됨에 따라, 이러한 환경 변경에도 영향을 받지 않는 솔루션이 필요했기 때문에, 가장 적합하다고 생학한 Docker 를 사용하기로 했음
        + 기존 배포에서 war파일로 배포하고잇었기 때문에, 이를 톰캣에서 실행하기 위해 기본 이미지를 tomcat 기반으로 했고, entrypoint.sh파일을 두어 해당 파일에서 catalina쉘을 실행시키도록 Docker image구성
        + 서비스 실행에 웹 어플리케이션 서버, 웹 어플리케이션용 DB서버, 데이터용 DB서버 총 3가지가 필요 하였으므로, 이 3가지를 Docker Compose로 관리
        + 웹 어플리케이션 서버의 이미지는 CircleCI를 통해 만들어지고 Artifactory로 백업된 이미지를 사용하였고, DB 이미지는 mysql 5.7, 데이터용 DB이미지는 postgres:12.3을 사용
        + CircleCI 내부에서 maven 빌드를 통해 war를 들고 도커이미지가 만들어짐
        + jib플러그인 쓰면 바로 도커파일 뽑을수있었을텐데, 이 방법을 나중에 알았음
        
    * Ansible
        + Dashboard 서비스를 실행하기 위해서는 DB서버등 같이 배포 및 실행 되어야할것들이 있었는데, 이를 한꺼번에 묶어 서비스 프로비저닝을 하기 위해 사용 
        + 기존에는 서버 1대로 작업 하였지만, 가용 서버가 늘어나서(개발서버1&2,스테이징 서버, 운영서버) 각 서버에 적절하게 배포할 방법이 필요했음
        + 스테이징 서버에 Ansible tower를 구성해두고 각 서버들을 타겟으로 두고 playbook을 작성 함으로써 각 서버에 배포 하도록 했음
        + 플레이북에 적용할 호스트를 지정한 후, 서비스 구동에 필요한 동작들(백업되어있는 db copy & 해당 copy된 db로 서비스 실행, Artifactory에 저장된 docker image 다운을 위해 환경설정, docker compose 실행)을 저장 하고 수행하도록 지정
        + 적절한 when 옵션으로 변경점이 있을때만 실행되게 하여 DB 인스턴스는 서버가 변경되었다고 해서 무조건 재시작되지는 않았음
        + Ansible이란 Python기반의 자동화 관리 도구로, yml기반의 플레이북을 작성하여 어떤 동작을 수행할것인지 정하고, 해당 동작을 Target 에 SSH 기반의 Push를 함으로써 Agentless하게 동작할 수 있음

    * Ansible Vs Jenkins
        + Ansible: 어플리케이션 배포 및 인프라 자동화, CD 즉 배포 자동화 및 환경 설정에 더 초점이 있음
        + Jenkins: 빌드 및 릴리스 프로세스 자동화, CI 즉 빌드 자동화에 좀 더 초점이 있는 도구

    * Artifactory
        + 아티팩트 저장소
        + CircleCI를 통해 특정 태그가 달린 commit이 들어올때마다, Docker image를 만들어서 Artifactory에 저장 되도록 하였음
        + Ansible에서도 이 Artifiactory에 저장된 Docker imager를 통해 서비스를 구축했음

- 역할
    * 서비스 Dockerize
    * REST API 설계 및 구현
        + 기존과 동일하게 지표별로 서비스를 구성하려고 하였으나, 각 사업부별 요구사항이 달라서 도저히 분리 할수가 없었음
        + 하지만 사업부별 API는 동일하고 내부 로직이 다르다는것에 착안하여 사업부 서비스 인터페이스를 만들고, 그 구현체를 두어 필요한경우 오버라이딩 하여서 구현 하도록 하였음
        + 초반에는 이 설계가 괜찮았으나, 해외연구소도 지원함에 따라 너무 많은 서비스 구현체를가지게 되었음
        + 그래서 다시 기존 설계처럼 지표별로 서비스를 구성하기 위해 리팩토링 중

    * CircleCI + Artifactory를 이용한 서비스 Docker Image 관리 체계 구축
    * Ansible을 통한 서비스 Provisioning 체계 구축
    * 데이터 관련
        + 데이터의 양이 상당히 많아졌으나, 이를 직접 다루지는 않았고 Splunk REST API를 통해서 쿼리를 던지고 이를 이용해 데이터를 받아봣음
        + 또 계산이 오래걸리는 로직등이 있어, 데이터를 담당하시는 분이 매일 데이터를 가공해 정제된 형태로 PostgreSQL DB에 넣어주면 그걸 이용해서 보여줫음
    * 국체화 관련
        + 사용자 로그인시 BE에서 User 테이블을 확인, 해당 사용자의 기본 언어를 확인함
        + Token에 해당 정보를 담아서 FE로 보내주면 FE가 그 언어에 맞게 i18n 구현한거에 따라서 변경했음
        + 기본 언어를 변경하는 API도 있어서, 사용자가 언어 변경시 반영되도록 해놨음
    * 권한관리 관련
        + 원래 정석대로라면 Spring Security써서 Security Config에 hasRole체그 하곤 했어야 했는데 권한 구조상 이게 적합하지 않다고 판단했음
        + 접속 가능한 페이지 + 접속 가능한 조직 이 같이 매핑됬어야 했기 때문에 그랬음
        + 권한관리는 FE / BE 양쪽 모두에서 관리했음
        + User테이블 / 권한 테이블 / User 별 권한 테이블 / 권한별 접속가능 URL 테이블 / 조직도 테이블 로 나눠서 해당 유저가 로그인시 그 유저의 권한을 체크하고 그 권한이 가지는 접속 가능한 페이지와 그 유저가 볼수있는 조직 리스트를 토큰에 담아서 반환했음
        + FE에선 그 정보를 들고 그 유저가 접속 불가능한 조직 or 접속 불가능한 URL로 접근시 리다이렉션되게 막았음
        + 겸직 조직장 같은 경우는 해당 구조상 한 조직에 대한 권한만 가질 수 있어서 문제가 발생해서, 겸직 조직장 리스트를 만들어 따로 관리하며 겸직 조직들의 공통 상위 조직의 권한을 줘서 임시로 해결했음 -> 이거 때문에 이 조직 구조 가진걸 Refactoring 하려 했지만 그 전에 퇴사 해버렸음

- 성과
    * 삼성전자 Set부문 S/W 개발인력 ( 약 10000명 ) 데이터 수집 및 각 5개 사업부 및 Samsung Research 소속 11개 해외연구소 View 제공
    * 삼성전자 Set부문 각 조직장 및 SE 담당자 ( 약 2000명 ) 대상 서비스
    * 삼성전자 DS부문 기술이전(예정)

- 개인적 성취
    * 서비스 Dockerize 및 Docker Image 관리에 대한 경험
    * Artifactory, Ansible 등 Framework에 대한 경험
    * 서비스 Provisioning 에 대한 경험

- 서비스 상세 소개
    * 기존 개발 데이터 가시화 Dashboard 서비스의 관리자 View를 강화하여 전사 조직장 및 SE 담당자들에게 제공하는 서비스
    * 각 조직 별 코드리뷰 현황 및 구조품질 분석 현황, 단위시험 현황 제공으로 조직장에게 해당 조직의 S/W 품질 모니터링 체계 제공


# 개발 데이터 가시화 Dashboad

- 주요 사용 기술
    * Spring Boot
    * Jenkins
        + 배포 용도로 활용 했음
        + Jenkins 서버에 slave로 개발서버, 운영서버등을 slave로 붙여 git에 저장된 코드를 받아 build한 후 실행 하도록 구성

    * CircleCI
        + 사내 Github과 연동하여 Regretion Test용도로 활용했음
        + PR이 만들어질 경우 CircleCI서버의 도커 인스턴스에서 적절하게 빌드후, Unit test를 실행, 해당 결과를 PR에 훅으로 알려주도록 구성
        + Branch Protection Rule을 적용해서 CircleCI에서 수행한 Test가 Pass 하지 못했을경우 PR이 Merge되지 못하도록 하여 안정성 확보
        + CircleCI 특성상 매번 도커인스턴스가 만들어지고 거기서 빌드 & 테스트가 이뤄지기 때문에, 그때마다 빌드를 하기엔 너무 오래걸려 사내 maven cache 저장소를 이용해서 시간을 줄임

- 역할
    * Spring Boot Server 구조 설계
        + MVC 패턴을 따르면서 어떻게 Controller와 Service를 구성할지에 대해서 고민을했음
        + 먼저 개인별 페이지를 준비하며, Dashboard에서 보여주는 지표별로 Controller를 구분 지었고, 그에 따른 서비스들이 매핑 되도록 구성 했음
        + 이후 프로젝트별 서비스에서는, 프로젝트는 개인이 모여서 구성된다라는것에 착안해, 개인별 페이지에서 사용한 서비스를 확장하여 프로젝트별 기능을 구현하도록 만든다음에, 프로젝트 컨트롤러에서 해당 서비스가 불려지도록 만듬
        + 이후 팀별 서비스도, 프로젝트들이 모여 팀을 구성한다라는것에 착안해 동일하게 구성했음
        + 하지만 급격하게 요구사항이 변경되고 추가되는것이 많고, 특정 상황에서만 로직이 변경되어야 하는등의 문제점으로 인해 중복코드가 많이 발생했음
        + 그래서 현재는 최대한 중복 코드를 줄이는 방향으로 리팩토링 하면서, 공통적으로 반복되는것(권한 체크, 로깅 등)은 AOP를 활용해서 사용 할 수 있도록 변경중

    * REST API 설계 및 구현
        + Dashboard였기 때문에 대부분의 REST API가 GET이였음(유저 등록 / 삭제쪽에나 POST / DELETE정도만 있었음)
        + Visualization이였기 때문에 보여주려는 형식에 따라 데이터도 변해야 했는데, 이럴 경우 요구사항이 변경되어 그래프만 변경되어도 Backend 코드까지 같이 수정되어야 했었음
        + 잘 생각해본 결과 데이터가 3가지 모양새( 트렌드 처럼 연속되는 경우, 막대그래프처럼 특정 속성에 따른 값들이 뭉쳐있는 형태, 표 처럼 특정 속성들의 값이 나열된 형태)로 구성될 수 있었기 때문에, 이 3가지에 대한 공통적인 Format을 구성해서 각 API별로 저 Foramt대로 반환할 수 있도록 하여 FE와의 Dependency를 줄였음
        + swagger등을 이용해 FE와 소통하며 API설계를 맞춰나감

    * JIRA / Confluence 등 외부 시스템 연동
        + 기본적으로 모든 데이터는 Splunk를 통해 가져왔음(Splunk REST API사용)
        + 거의 모든 데이터를 Slpunk의 SQL문인 SPL을 작성해 가공하여서 들고 왔는데, 데이터의 join이 많을경우 현저하게 느려지는 문제가 발생했음
        + 따라서 JIRA등의 데이터는 직접 JIRA REST API를 활용하는것이 빠르다고 판단, JIRA REST API를 통해 가져오도록 변경하였음
        + 이처럼 데이터 소스가 늘어남에 따라 각 데이터 소스별 포맷이 다른 문제가 발생하여, 이를 해결하고자 Template패턴을 사용해 데이터를 가져오는 Template를 만든 후 각 데이터 소스별 구현체를 두어 모두 일정한 포맷으로(JSON)반환 하도록 바꿧음

    * DB 설계
        + User정보, 팀정보, 프로젝트 정보, 릴리즈 정보등 저장해야할 정보가 많았고, 앞서 말했던 Splunk의 느린 문제점이 있어 추후엔 데이터용 캐시 DB도만들어서 구현해뒀음
        + 캐시 DB는 하기 Crawler가 주기적으로 데이터를 수집 & 업데이트 함으로써 관리되도록 하였음
        + 먼저 요구사항을 정의 해보고, 그 요구사항에서 명사를 기반으로 개체(Entity)와 속성(Attribute)를 추출하고, 동사를 기반으로 개체 사이의 관계를 추출해서 설계
        + 객체를 테이블로 만들고, 1대다 관계는 다쪽에 외래키, 1대1은 외래키 주고받고 다대다는 테이블로 구성하고 이런식으로 구현
        + 처음엔 외래키 지정 다 해줬지만, 개발 하면서 요구사항이 계속 바뀌는 바람에 자주 데이터 컨버젼이 이뤄졌고, 그때마다 너무 힘들었어서 나중엔 데이터 정합이 필요한 부분 아니면 다 제거 했음

    * Splunk REST API 및 Crawler 구현으로 데이터 수집 자동화
        + 개인별 서비스를 제공할때에는 괜찮았으나, 프로젝트별 데이터를 제공할때에는 SPL문만으로는 데이터를 가져오는데 너무 오래걸렸음
        + 그래서 Splunk REST API를 활용해서 데이터를 주기적으로 수집해 캐시 DB에 채워줄 Crawler를 구현 했음
        + 주기적으로 데이터 수집하는것 외에도 비 정기적으로 데이터 수집 및 업데이트가 필요 했기 때문에 이를 서버의 REST API를 통해 호출하면 어떨까 해서 서버내에 Crawler 서비스를 따로 만들어 해당 서비스를 Scheduled 태그를 이용해 매일마다 수집하게 했고, 필요시 해당 서비스를 호출 할 수 있도록 REST API도 만들어 두었음

    * Jenkins 를 통한 빌드 및 배포 자동화
    * Test Case 작성 및 CircleCI를 활용한 Regression Test환경 구성
        + Release를 하기 위해서는 삼성 내부의 룰을 만족 해야 했음(Coverage 몇 %, 잠재결함 몇건 이하 등)
        + 그래서 TC작성이 필요 했기 때문에, 역으로 TDD방식으로 요구사항에 맞게 TC를 먼저 작성해서 해당 TC가 통과되도록 코드를 구성 하였음
        + 하지만 TC내부에서 Assetion을 할때 Response 체크정도만 하는 정도로 끝나는경우도 많아서 이런 TC만으론 품질을 확보할 수 없다고 생각
        + Gold master TC를 만들어 안정된 상태의 Response를 기록하고 이를 비교하는 TC를 만들어서 품질도 확보하며 안정성을 높였음
    * FE 관련
        + FE는 Angular로 되어있고 FE 작업을 주로 하진 않고 급한거 정도만 간단하게 하는 형식으로 조금씩만 함
        + 따로 Kibana같은 Visualize Tool을 쓴건 아니고 그냥 Apache Echart Library를 사용
    * 서비스 배포 관련
        + 서비스 배포를 할때마다 Jenkins에서 빌드와 배포를 같이 하기에 서비스의 다운타임이 5분정도 됬었음
        + 그래서 일단 다운타임을 줄이고자 빌드잡 / 배포잡으로 나눳음
        + 이것도 근본적인 해결책은 아니다보니깐 Nginx + Docker 로 무중단 배포를 해보려고 구성을 했음
        + 그래서 일단 서비스 Dokcerize 했는데, 다른 업무에 밀려서 Nginx까지는 가지 못했음
   
- 성과
    * Samsung Research S/W 개발인력 ( 약 1000명 ) 대상 서비스 제공
    * TPS는 따로 측정하진 않았고 일별 Unique User Count 정도만 셋는데, 한 50~100명...
    * Samsung Research 19년 31개 과제 159개 Release 품질 View 제공 및 Release의 품질 Monitoring 도구로 활용
    * Samsung Research 소속 8개 팀 조직별 View제공 및 임원 주간회의 시 자료로 활용

- 개인적 성취
    * Spring Framework에 대한 이해도 증가 및 Spring Security, Hibernate등 다양한 Framework 경험
    * REST API 설계 및 구현, 검증에 대한 경험
    * 효율적 CI/CD 구축에 대한 경험 획득

- 서비스 상세 소개
    * Github, Gerrit 등 버전 관리 시스템에서 발생하는 개발 데이터 및 Jira에서 발생하는 이슈 데이터를 수집
    * 사내 Release 관리 시스템에서 발생하는 Release 관리 데이터 및 정적 분석 도구등에서 발생하는 S/W 품질 관련 데이터 수집
    * 다양한 환경에 파편화 되어있는 데이터를 한 화면에서 시각화 하여 볼 수 있는 View를 제공 함으로써 개발자 및 관리자에게 Insight를 제공 하는 서비스
    * 개인별 / 프로젝트별 페이지를 제공함으로써 개인별 개발 데이터 및 개인에게 할당된 이슈 등 품질 현황 제공 및 프로젝트의 Release 현황 및 Release별 S/W 품질 정보 제공
    * 조직별 페이지를 통해 조직별 현황을 파악 가능하도록 하여 관리자의 의사결정 자료로 활용
