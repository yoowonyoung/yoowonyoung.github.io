---
layout: post
title: "Kafka CDC"
description: Kafka CDC
date: 2022-08-14 13:33:00 +09:00
categories: Kafka Study
---


# Kafka CDC

## CDC란?
- Change Data Capture, 변경 데이터 캡처란 데이터가 변경되는 시점과 해당 항목을 추적하고 이러한 변경에 대응해야하는 다른 시스템 및 서비스에 알림을 전송하는 검증된 데이터 통합 패턴
- 변경 데이터 캡처를 통해 데이터를 사용하는 모든 시스템에서 일관성과 기능을 유지할 수 있음

## CDC 동작 방식
- CDC는 데이터베이스 원본 테이블의 행 수준 변경사항(삽입, 업데이트, 삭제)을 추적 한 다음, 해당 데이터를 사용하는 다른 시스템이나 서비스에 변경 알림을 활성화 하는 방식
- 변경 알림은 데이터베이스에서 수행한 것과 같은 순서로 보내짐
- Kafka CDC는 이런 변경 알림을 kafka를 통해 consumer에게 보내는 것

## Kafka Connect
- Kafka Connect는 데이터 파이프라인 생성시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션
- 특정 작업 형태를 템플릿으로 만들어놓은 커넥터를 실행 함으로써 반복 작업을 줄일 수 있음. 파이프라인 생성시 자주 반복되는 값들(토픽 이름, 파일 이름, 테이블 이름 등)을 파라미터로 받는 커넥터를 코드로 작성하면, 이후에 파이프라인을 실행할때는 코드를 작설할 필요가 없기 때문
- 커넥터는 프로듀서 역할(데이터를 카프카 토픽으로 전송)을 하는 소스 커넥터, 컨슈머 역할(카프카 토픽에 있는 데이터를 처리)을 하는 싱크 커넥터 2가지로 나뉨
    * 이후 사용할 Debezium MySQL Connector가 소스 커넥터의 예시

- 사용자가 커넥트에 커텍터 생성 명령을 내리면 커넥트는 내부에 커넥터와 테스크를 생성
- 커넥터는 태스크들을 관리 하는데, 태스크는 커넥터에 종속되는 개념으로 실질적인 데이터 처리를 함. 따라서 각 태스크의 상태를 확인 해야함
- 커넥트는 1개 프로세스만 실행되는 단일 모드 커넥트와 2대 이상의 서버에서 클러스터 형태로 운영하는 분산 모드 커넥트의 방식으로 실행 가능
- REST API를 사용해 Connector를 등록하고 사용할 수 있다

## Debezium MySQL Connector
- Debezium MySQL Connector는 MySQL의 binlog를 읽어 INSERT, UPDATE, DELETE 연산에 대한 변경 이벤트를 만들어 Kafka 토픽으로 해당 이벤트를 전송
- MySQL은 일반적으로 지정된 시간이 지나면 binlog를 정리 하므로, Debezium MySQL Connector는 각 DB에 대해 초기 스냅샷(initial consistent snapshot)을 만들고 해당 스냅샷이 생성된 시점부터 binlog를 읽음
- 지원되는 MySQL topology
    - Standalone, Primary and replica, HA Cluster, Multi-primary, Hosted(AWS RDS, Aurora)
    - Hosted 에서는 global read lock을 지원하지 않으므로, 초기 스냅샷을 만들때 table-level lock이 사용됨

### Schema History topic
- DB의 스키마는 언제든지 바뀔 수 있기 때문에, 커넥터는 현재 기록되는 INSERT, UPDATE, DELETE 연산의 스키마에 대해서 알고 있어야 하며, 커넥터가 테이블의 스키마가 변경되기 전에 기록된 이벤트를 처리하고 있을수도 있으므로 현재 스키마만 알고 있어서는 안됨
- MySQL의 binlog는 DB에 적용된 DDL문까지 남기 때문에, 커넥터가 binlog를 읽다가 DDL문을 만나면 이 구문을 분석해서 메모리에 저장되어있는 각 테이블의 스키마를 업데이트
- 커넥터의 크래시가 발생 하거나 정상적으로 중지 된 후 재시작이 발생 하면 특정 시점부터 binlog를 다시 읽기 시작 하는데, 이때 Database history topic을 읽고 커넥터가 시작된 지점까지의 binlog의 DDL 구문을 분석해서 테이블 구조를 다시 만든다
- Database history topic은 커넥터만 사용

### Schema Change topic
- Debezium MySQL 커넥터를 이용해 스키마 변경 이벤트에 대해서도 카프카 토픽에 이벤트 발행이 가능
- 스키마 변경 이벤트 payload
    * ddl: CREATE, ALTER, DROP
    * databaseName
    * pos: binlog에서 해당 구문이 발견된 위치
    * tableChanges: 변경 이후의 테이블 스키마. 테이블의 각 열에 대한 항목이 포함된 배열 형식이며, JSON/Avro 형식

### SnapShot
- Snapshot mode
    * initial: 커넥터가 해당 서버에 대해서 offset이 기록되지 않은 경우에만 스냅샷을 실행
    * initial_only: 커넥터가 해당 서버에 대해서 offset이 기록되지 않은 경우에만 스냅샷을 실행, binlog로 부터 변경 이벤트를 읽지 않음
    * when_needed: 커넥터가 시작시 필요할 때 마다 스냅샷을 실행(offset을 사용할수 없거나, 기존 기록된 offset이 사용할 수 없는 binlog 위치를 가르키거나, GTID를 지정하는 경우)
    * never: 커넥터가 스냅샷을 실행하지 않음. 서버와 함께 시작이 되면 바로 binlog를 읽기 시작
    * schema_only: 커넥터가 데이터가 아닌 스키마에 대한 스냅샷을 실행. 커넥터가 실행 된 이후 변경 사항만 포함하고 싶은 경우에 유용
    * schema_only_recovery: 커넥터를 재시작 할 때 이 모드로 실행하면 손상되거나 손실된 database history 토픽을 복구할 수 있음

- Snapshot 만드는 flow - global read lock
    * global read lock으로 다른 DB client들의 write를 막음
    * Repeatable read 격리 레벨의 트랜잭션 시작
    * 현재의 binlog position 을 읽음
    * 설정된 DB와 테이블의 스키마를 읽음
    * global read lock을 반환함
    * (해당되는 경우에만) CREATE, DROP 등의 DLL문을 읽어 schema change topic에 기록
    * 데이터베이스 테이블을 검색해서 각 row에 대해 CREATE 이벤트를, 관련 테이블별 카프카 topic에 기록
    * 트랜잭션 commit
    * 완료된 스냅샷을 connector offset에 기록

- Snapshot 만드는 flow - table level lock
    * table level lock 획득 (LOCK TABLES 권한이 필요)
    * Repeatable read 격리 레벨의 트랜잭션 시작
    * DB와 테이블의 이름을 읽고 필터링
    * 현재의 binlog position 을 읽음
    * 설정된 DB와 테이블의 스키마를 읽음
    * (해당되는 경우에만) CREATE, DROP 등의 DLL문을 읽어 schema change topic에 기록
    * 데이터베이스 테이블을 검색해서 각 row에 대해 CREATE 이벤트를, 관련 테이블별 카프카 topic에 기록
    * 트랜잭션 commit
    * 완료된 스냅샷을 connector offset에 기록

### Topic 
- 토픽 이름은 ```<serverName>.<databaseName>.<tableName>``` 으로 구성

### Transaction metadata
- Debezium을 사용해 트랜젝션 바운더리 이벤트(트랜잭션의 시작, 종료에 대한) 이벤트 발행 가능

### Data Change Event
- Debezium MySQL Connector는 INSERT, UPDATE, DELETE 연산에 대한 데이터 변경 이벤트 발행를 만들 수 있다
- Debezium과 Kafka Connect는 연속적인 이벤트 메시지 스트림을 중심으로 설계 되었지만, 이벤트의 구조가 시간에 따라 변할수 있기 때문에 각 이벤트에는 스키마(또는 스키마 레지스트리를 사용중인 경우 스키마 레지스트리에서 스키마를 가져오는데 사용하는 스키마ID)가 포함
- 기본 Change Event 구조(설정에 따라 구조가 변경)

```json
{
 "schema": { 
   // 이벤트 키의 일부, 변경된 테이블의 primary key (primary key가 없는 경우 unique key) 에 대한 설명
  },
 "payload": { 
   // 이벤트 키의 일부, 변경된 row 의 key
 },
 "schema": { 
   // 이벤트 밸류의 일부, 변경된 row의 구조에 대한 설명
 },
 "payload": { 
   // 이벤트 밸류의 일부, 실제로 변경된 데이터
 },
}
```

- Update 이벤트 데이터 예시

```json
{
  "schema": { ... },
  "payload": {
    "before": { // 변경 전 데이터
      "id": 1004,
      "first_name": "Anne",
      "last_name": "Kretchmar",
      "email": "annek@noanswer.org"
    },
    "after": { // 변경 후 데이터
      "id": 1004,
      "first_name": "Anne Marie",
      "last_name": "Kretchmar",
      "email": "annek@noanswer.org"
    },
    "source": { 
      "version": "1.9.5.Final", // debezium 버전
      "name": "mysql-server-1", // 커넥터 이름
      "connector": "mysql", 
      "name": "mysql-server-1",
      "ts_ms": 1465581029100,
      "snapshot": false,
      "db": "inventory",
      "table": "customers",
      "server_id": 223344,
      "gtid": null,
      "file": "mysql-bin.000003",
      "pos": 484, // binlog 위치
      "row": 0,
      "thread": 7,
      "query": "UPDATE customers SET first_name='Anne Marie' WHERE id=1004"
    },
    "op": "u", // Operation, C = CREATE, U = UPDATE, D = DELETE
    "ts_ms": 1465581029523 
  }
}
```

### MySQL 설정
- mysql user에 필요한 권한
    * SELECT: 스냅샷 만들때 데이터베이스로부터 Row를 읽기 위해 필요
    * RELOAD: 스냅샷 만들때 FLUSH 또는 내부 캐시를 비우기 위해 필요
    * SHOW DATABASES: 스냅샷 만들때 필요
    * REPLACTION SLAVE: MySQL Server의 binlog에 접근하기 위해 필요
    * REPLACATION CLIENT: 커넥터가 SHOW MASTER STATUS, SHOW SLAVE STATUS, SHOW BINARY LOGS를 사용 해야 하므로 필요

- binlog 설정이 잘 되어있는지 확인
- GTID는 필수는 아니지만, Replication 과정에서 Replica 서버가 일치하는지 보다 쉽게 확인 가능하게 해주는 옵션이므로 쓰면 좋다

### MySQL Connector 설정 및 주요 옵션
```json
{
    "name": "inventory-connector", // Kafka Connect에 등록할 커넥터 이름
    "config": {
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",  // 커넥터 클래스 명
        "database.hostname": "192.168.99.100", // MySQL 서버 주소
        "database.port": "3306",  // MySQL 서버 포트
        "database.user": "debezium-user",  // MySQL 유저
        "database.password": "debezium-user-pw", // MySQL 유저 비밀번호
        "database.server.id": "184054", // 커넥터의 Unique ID
        "database.server.name": "fullfillment", // MySQL 서버(혹은 클러스터)의 Logical name
        "database.include.list": "inventory",  // MySQL 서버에 의해 제공되는 DB 목록
        "database.history.kafka.bootstrap.servers": "kafka:9092",  // kafka broker 목록. 커넥터가 database history topic에 쓰거나, database history topic을 이용해 복구 할때 필요
        "database.history.kafka.topic": "dbhistory.fullfillment",  // database history topic 의 이름. 내부적으로만 사용되고, consumer에 의해 사용될일은 없다
        "include.schema.changes": "true" // DDL 변경에 대해서 이벤트를 만들지것인지
    }
}
```

- table.include.list: 콤마(,) 구분자 문자열, 변경 감지를 할 테이블 목록. 기본적으로 시스템 테이블을 제외한 모든 테이블에 대한 변경이 캡쳐 됨. 서로 상반되는 table.exclude.list 와 동시에 설정하지 말것
- column.include.list: 콤마(,) 구분자 문자열. 값 변경을 감지할 컬럼 목록. Fully-qualified name으로 써야함(databaseName.tableName.columnName 의 형식)
- include.query: 변경을 발생시킨 쿼리를 이벤트 데이터에 포함시킬지 여부. true로 설정시, MySQL의 binlog_rows_query_log 설정도 같이 ON 시켜야 함

## Ref
- CDC란?, CDC 동작 방식: https://www.redhat.com/ko/topics/integration/what-is-change-data-capture
- Kafka Connect: 아파치 카프카 애플리케이션 프로그래밍
- Debezium Connector: https://debezium.io/documentation/reference/stable/connectors/mysql.html
