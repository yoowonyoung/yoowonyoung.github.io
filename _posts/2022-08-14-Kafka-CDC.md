---
layout: post
title: "Kafka CDC"
description: Kafka CDC
date: 2022-08-14 13:33:00 +09:00
categories: Kafka Study
---


# Kafka CDC

## CDC란?
- Change Data Capture, 변경 데이터 캡처란 데이터가 변경되는 시점과 해당 항목을 추적하고 이러한 변경에 대응해야하는 다른 시스템 및 서비스에 알림을 전송하는 검증된 데이터 통합 패턴
- 변경 데이터 캡처를 통해 데이터를 사용하는 모든 시스템에서 일관성과 기능을 유지할 수 있음

## CDC 동작 방식
- CDC는 데이터베이스 원본 테이블의 행 수준 변경사항(삽입, 업데이트, 삭제)을 추적 한 다음, 해당 데이터를 사용하는 다른 시스템이나 서비스에 변경 알림을 활성화 하는 방식
- 변경 알림은 데이터베이스에서 수행한 것과 같은 순서로 보내짐
- Kafka CDC는 이런 변경 알림을 kafka를 통해 consumer에게 보내는 것

## Kafka Connect
- Kafka Connect는 데이터 파이프라인 생성시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션
- 특정 작업 형태를 템플릿으로 만들어놓은 커넥터를 실행 함으로써 반복 작업을 줄일 수 있음. 파이프라인 생성시 자주 반복되는 값들(토픽 이름, 파일 이름, 테이블 이름 등)을 파라미터로 받는 커넥터를 코드로 작성하면, 이후에 파이프라인을 실행할때는 코드를 작설할 필요가 없기 때문
- 커넥터는 프로듀서 역할(데이터를 카프카 토픽으로 전송)을 하는 소스 커넥터, 컨슈머 역할(카프카 토픽에 있는 데이터를 처리)을 하는 싱크 커넥터 2가지로 나뉨
    * 이후 사용할 Debezium MySQL Connector가 소스 커넥터의 예시

- 사용자가 커넥트에 커텍터 생성 명령을 내리면 커넥트는 내부에 커넥터와 테스크를 생성
- 커넥터는 태스크들을 관리 하는데, 태스크는 커넥터에 종속되는 개념으로 실질적인 데이터 처리를 함. 따라서 각 태스크의 상태를 확인 해야함
- 커넥트는 1개 프로세스만 실행되는 단일 모드 커넥트와 2대 이상의 서버에서 클러스터 형태로 운영하는 분산 모드 커넥트의 방식으로 실행 가능
- REST API를 사용해 Connector를 등록하고 사용할 수 있다

## Debezium MySQL Connector
- Debezium MySQL Connector는 MySQL의 binlog를 읽어 INSERT, UPDATE, DELETE 연산에 대한 변경 이벤트를 만들어 Kafka 토픽으로 해당 이벤트를 전송
- MySQL은 일반적으로 지정된 시간이 지나면 binlog를 정리 하므로, Debezium MySQL Connector는 각 DB에 대해 초기 스냅샷(initial consistent snapshot)을 만들고 해당 스냅샷이 생성된 시점부터 binlog를 읽음
- 지원되는 MySQL topology
    - Standalone, Primary and replica, HA Cluster, Multi-primary, Hosted(AWS RDS, Aurora)
    - Hosted 에서는 global read lock을 지원하지 않으므로, 초기 스냅샷을 만들때 table-level lock이 사용됨

### Schema History topic
- DB의 스키마는 언제든지 바뀔 수 있기 때문에, 커넥터는 현재 기록되는 INSERT, UPDATE, DELETE 연산의 스키마에 대해서 알고 있어야 하며, 커넥터가 테이블의 스키마가 변경되기 전에 기록된 이벤트를 처리하고 있을수도 있으므로 현재 스키마만 알고 있어서는 안됨


## Ref
- CDC란?, CDC 동작 방식: https://www.redhat.com/ko/topics/integration/what-is-change-data-capture
- Kafka Connect: 아파치 카프카 애플리케이션 프로그래밍
- Debezium Connector: https://debezium.io/documentation/reference/stable/connectors/mysql.html
