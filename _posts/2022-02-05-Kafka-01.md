---
layout: post
title: "Apache Kafka Application Programming - 3: 카프카 기본 개념 설명"
description: 카프카 기본 개념 설명
date: 2022-02-05 13:37:00 +09:00
categories: Kafka Study
---


# 카프카 기본 개념 설명

## 카프카 브로커, 클러스터, 주키퍼
- 카프카 브로커는 카프카 클라이언트와 데이터를 주고 받기 위해 사용하는 주체. 데이터를 분산 저장하여 장애가 발생 해도 안전하게 사용할 수 있도록 해주는 애플리케이션. 하나의 서버에는 하나의 카프카 브로커 프로세스가 실행 되지만, 데이터를 안전하게 보관하고 처리하기위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영. 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산저장하고 복제하는 역할

### 데이터 저장, 전송
- 프로듀서로부터 데이터를 전달 받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장. 컨슈머가 데이터를 요청하면 파티션에 저장된 데이터를 전달. 프로듀서로부터 전달된 데이터는 파일 시스템에 저장
- 카프카는 메모리나 데이터베이스에 저장하지 않으며 따로 캐시 메모리를 구현하여 사용하지도 않음
- 파일시스템에 저장하기 때문에 파일 입출력으로 인해 이슈가 발생하지 않을까 하지만, 카프카는 페이지 캐시를 사용하여 디스크의 입출력 속도 문제를 해결. 
    * 페이지 캐시: OS에서 파일 입출력 성능의 향상을 위해 만들어 놓은 메모리 영역

### 데이터 복제, 싱크
- 데이터 복제는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력. 클러스터로 묶인 브로커중에서 일부에 장애가 발생 하더라도 데이터를 유실하지 않고 안전하게 사용 가능
- 카프카의 데이터 복제는 파티션 단위로 이뤄짐. 토픽을 생성 할 때 파티션의 복제 갯수(replication factor)도 같이 설정 되는데, 직접 선택하지 않으면 브로커에 설정된 옵션을 따라감(1 ~ 브로커 갯수 까지 가능. 1은 복제 없음)
- 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워 라고 하며, 팔로워들은 리더의 오프셋을 확인해서 현재 자신이 가지고 있는 오프셋과 차이가 있는 경우 리더 파티션으로부터 데이터를 가져와 자신의 파티션에 저장하는데 이것이 복제임
- 파티션 복제로 인해 나머지 브로커에도 파티션의 데이터가 복제되므로 복제 개수만큼 용량이 증가하는 단점이 있으나, 복제를 통해 데이터를 안전하게 사용 할 수 있다는 장점이 있음
- 리더 파티션에 장애가 발생한 경우 나머지 팔로워 파티션중 하나가 리더 파티션 지위를 넘겨 받음. 운영시에는 데이터 종류마다 다른 복제 개수를 설정하고 상황에 따라서는 토픽마다 복제 개수를 다르게도 가능
- 컨트롤러: 클러스터의 다수의 브로커중 한대가 컨트롤러 역할. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배. 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할
- 데이터 삭제: 카프카는 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않고, 컨슈머나 프로듀서가 데이터 삭제 요청을할 수 없음. 오직 브로커만이 데이터를 삭제 가능. 데이터 삭제는 파일 단위로 이뤄 지는데 이 단위를 로그 세그먼트라고 부름. 세그먼트에는 다수의 데이터가 들어 있어 일반적인 데이터 베이스처럼 특정 데이터를 선별해서 삭제할 수 없음. 데이터가 쌓이는동안엔 파일시스템으로 부터 세그먼트가 열리게 되며, 특정 용량이 되면 세그먼트가 닫힘. 닫힌 세그먼트만 삭제 가능
- 컨슈머 오프셋 저장: 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋. 커밋한 오프셋은 __consumer_offsets 토픽에 저장. 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리
- 코디네이터: 클러스터의 다수의 브로커중 한대는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 코디네이터의 역할. 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 다른 컨슈머로 할당하는 리밸런스 과정을 거침
- 주키퍼는 카프카의 메타데이터(카프카 브로커에 대한 정보, 카프카에 저장된 토픽 등)를 관리하는 역할

## 토픽과 파티션
- 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위. 토픽은 1개 이상의 파티션을 소유. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되어 있는데 이것을 레코드 라고 부름(레코드는 오프셋, 메시지키, 메시지값을 가지고 있음)
- 파티션은 카프카 병렬처리의 핵심으로 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있게 매칭
- 컨슈머 개수를 늘리면서 파티션 개수를 늘리면 처리량이 증가함
- 파티션은 큐와 동일하개 FIFO 구조이지만, 컨슈머가 데이터를 가져간다 하더라도 삭제되지는 않으며, 파티션의 레코드는 컨슈머가 가져가는것과는 별개로 관리되기 때문에  토픽의 레코드에는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있음

### 토픽 이름 제약 조건
- 빈 문자열 토픽 이름은 지원하지 않음
- 토픽 이름은 마침표 하나(.) 또는 둘(..)로 생성 될 수 없음
- 토픽 이름의 길이는 249자 미만
- 토픽 이름은 영어 대소문자와 숫자, 그리고 마침표(.), 언더바(_), 하이픈(-)조합으로 가능
- 카프카 내부 로직 관리 목적의 토픽(__consumer_offsets, __transtaction_state)와 동일하게는 불가
- 이름에 마침표(.)와 언더바(_)가 동시에 들어가면 안됨(생성은 가능하지만 경고)
- 이미 생성된 토픽의 이름을 마침표를 언더바로 바꾸는거나, 언더바를 마침표로 바꾸는것과 동일한 이름으로는 생성 불가

### 의미있는 토픽 이름 작명법
- 토픽의 이름을 통해 어떤 개발환경에서 사용되는것인지, 어떤 에플리케이션에서 어떤 데이터 타입으로 사용되는지 유추 가능해야함
- JIRA 티켓 번호를 토픽 이름에 넣는것도 좋은 방법
- 카프카 클러스터가 2개 이상이면 구분하기 위해 클러스터 이름을 넣어도 됨
- 예시
    * ```<환경>.<팀명>.<애플리케이션명>.<메시지타입>```
    * ```<프로젝트명>.<서비스명>.<환경>.<이벤트명>```
    * ```<환경>.<서비스명>.<JIRA번호>.<메시지타입>```
    * ```<카프카클러스터명>.<환경>.<서비스명>.<메시지타입>```

## 레코드
- 레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성
- 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장
- 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제
- 타임스탬프는 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이지만, 프로듀서가 레코드를 생성할때 임의의 타임 스탬프 값을 설정할 수 있고, 토픽 설정에 따라 브로커에 적재된 시간(LogAppendTime)으로도 설정 가능
- 메시지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해 사용. 프로듀서가 토픽에 레코드를 전송할 때 메시지 키의 해시값으로 파티션을 지정(동일한 메시지키라면 동일한 파티션)
- 메시지 값에는 실질적으로 처리할 데이터들이 들어기 있는데, 메시지 키와 메시지 값은 직렬화 되어 브로커로 전송되기 때문에 컨슈머가 이용 할때는 역직렬화 해야함
- 레코드의 오프셋은 0 이상의 숫자로, 직접 지정이 불가능 하고, 브로커에 저장될떄 이전에 저장된 레코드의 오프셋 +1 값으로 생성
- 헤더는 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도. 키/값의 형태로 데이터를 추가하여 레코드의 속성을(스키마 버전)등을 저장하여 컨슈머에서 참조 가능

## 카프카 클라이언트

### 프로듀서 API
- 카프카에서 데이터의 시작점은 프로듀서
- 프로듀서 애플리케이션은 카프카에 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송(리더 파티션을 가지고 있는 카프카 브로커와 직접 통신). 프로듀서를 구현하는 가장 기초적인 방법은 카브카 클라이언트를 라이브러리로 추가하여 자바 애플리케이션을 만드는것
- 프로듀서는 데이터를 직렬화 하여 카프카 브로커로 보내기 때문에 자바에서 선언 가능한 모든 형태를 브로커로 전송할 수 있음
- 프로듀서 중요 개념
    * 프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거침
    * KafkaProducer 인스턴스가 send메서드를 호출하면 레코드가 파티셔너에서 토픽의 어느 파티션으로 전송될것인지 정해짐
    * 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 accumulator에 데이터를 버퍼로 쌓아놓고 발송. 버퍼로 쌓인 데이터는 배치로 묶어서 전송함으로써 카프카의 프로듀서 처리량을 향상시키는데에 도움
    * 프로듀서 API를 사용하면 UniformStickyPartitioner와 RoundRobinPartitioner가 제공(UniformStickyPartitioner가 기본)
    * 카프카 클라이언트 라이브러리에서는 사용자 지정 파티셔너를 생성하기 위한 Partitioner 인터페이스가 제공됨
    * 카프카 프로듀서는 압축 옵션을 통해 브로커로 전송시 압축 방식을 정할수도 있음(압축시에도 리소스가 사용되고, 압축 해제시에도 컨슈머의 리소스가 사용되니 주의)

- 프로듀서 주요 옵션
    * 필수옵션
        + bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트이름:포트를 1개 이상 작성. 2개 이상으로 작성해서 일부 브로커에 이슈가 발생하더라도 접속하는데 이슈가 없도록 할수 있음
        + key.serializer: 레코드의 메시지 키를 직렬화 하는 클래스를 지정
        + value.serializer: 레코드의 메시지 값을 직렬화 하는 클래스를 지정

    * 선택 옵션
        + acks: 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는데 사용하는 옵션
        + buffer.memory: 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리 양
        + retries: 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수
        + batch.size: 배치로 전송할 레코드 최대 용량을 지정
        + ligner.ms: 배치를 전송하기전까지 기다리는 최소 시간
        + partitioner.class: 레코드를 파티션에 전송할떄 적용하는 파티셔너 클래스 지정
        + enable.idempotence: 멱등성 프로듀서로 동작할지 여부를 설정
        + transactional.id: 프로듀서가 레코드를 전송할때 레코드를 트랜잭션 단위로 묶을지 여부를 설정

- 메시지 키를 가진 데이터를 전송하는 프로듀서
    * 메시지 키가 포함된 레코드를 전송하고 싶다면 레코드 생성시 파라미터로 추가 해야함. 토픽 이름, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 생성할 경우 메시지 키가 지정됨(메시지 키가 지정된 데이터는 kafka-console-consumer 명령을 통해 확인 가능)
    * 파티션을 직접 지정하고 싶다면 토픽 이름, 파티션 번호, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 생성하면 됨(파티션 번호는 토픽에 존재하는 파티션 번호여야 함)

- 커스텀 파티셔너를 가지는 프로듀서
    * 커스텀 파티셔너를 지정한 경우 ProducerConfig의 PARTITIONER_CLASS_CONFIG 옵션을 사용자 생성 파티셔너로 설정해서 KafkaProducer인스턴스를 생성해야 한다

- 브로커 정상 전송 여부를 확인하는 프로듀서
    * KafkaProducer의 send 메서드는 Future객체를 반환 하는데, 이 객체는 RecordMetadata의 비동기 결과를 표현한것으로 레코드가 카프카 브로커에 정상적으로 적재 되었는지에 대한 데이터가 포함 되어 있음
    * Future의 get메서드로 프로듀서로 보낸 데이터의 결과를 동기적으로 가져 올 수 있음. 레코드가 브로커에 정상적으로 적재 되었다면 토픽 이름과 파티션 번호, 오프셋 번호가 출력 됨
    * 동기로 전송 결과를 확인하는것은 빠른 전송에 허들이 될 수 있으므로 비동기 CallBack이 제공되며 사용자 정의 Callback 클래스를 생성해서 레코드의 전송 결과에 대응하는 로직을 만들 수 있고, onCompletion 메서드를 통해 레코드의 비동기 결과를 받아올 수 있음
    * 데이터의 순서가 중요 하다면 동기로 전송 결과를 기다려야함

### 컨슈머 API
- 프로듀서가 전송한 데이터는 카프카 브로커에 적재. 컨슈머는 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리
- 컨슈머 중요 개념
    * 토픽의 파티션으로부터 데이터를 가져가기 위해 1개 이상의 컨슈머로 이뤄진 컨슈머 그룹을 운영 하거나, 토픽의 특정 파티션만 구독하는 컨슈머를 운영 할 수 있음
    * 컨슈머 그룹으로 운영하면 격리된 환경에서 안전하게 운영 가능. 컨슈머 그룹으로 묶인 컨슈머들은 1개 이상의 파티션들에 할당되어 데이터를 가져갈 수 있는데, 컨슈머 그룹의 컨슈머 갯수는 가져가고자 하는 토픽의 파티션 개수보다 작거나 같아야 함
    * 컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가지고 있어서, 카프카 프로듀서가 보낸 데이터를 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 처리 할 수 있다는 장점
    * 컨슈머 그룹의 컨슈머에 장애가 발생하면, 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에게 소유권이 넘어감(리밸런싱 - 컨슈머가 추가될때도 리밸런싱이 일어남. 리벨런싱은 언제든지 일어날 수 있으므로 데이터 처리중 리뱔런싱에 대응하는 코드를 작성 해야함)
    * 컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갓는지 커밋을 통해 기록(오프셋 커밋)
    * 오프셋 커밋은 컨슈머 애플리케이션에서 명시적, 비명시적으로 수행할 수있는데, 기본 옵션은 poll 메서드가 수행될 때 일정 간격마다 오프셋을 커밋하도록 되어있음(비명시 오프셋 커밋)
    * 비명시 오프셋 커밋은 poll이후에 리밸런싱 또는 컨슈머 강제종료 발생시 컨슈머가 처리하는 데이터가 중복 또는 유실이 발생 할 수 있으므로 주의 해야함
    * 명시적으로 오프셋을 커밋 하려면 poll메서드 호출 이후에 반환받은 데이터의 처리가 완료되고 commitSync 메서드를 호출 하면 됨

- 컨슈머 주요 옵션
    * 필수옵션
        + bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트이름:포트를 1개 이상 작성. 2개 이상으로 작성해서 일부 브로커에 이슈가 발생하더라도 접속하는데 이슈가 없도록 할수 있음
        + key.deserializer: 레코드의 메시지 키를 역직렬화 하는 클래스를 지정
        + value.deserializer: 레코드의 메시지 값을 역직렬화 하는 클래스를 지정

    * 선택 옵션
        + group.id: 컨슈머 그룹 아이디를 지정. subscribe 메서드로 토픽을 구독하여 사용할때는 이 옵션을 필수로 넣어야함
        + auto.offset.reset: 컨슈머 그룹이 특정 파티션을 읽을때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지를 선택하는 옵션
        + enable.auto.commit: 자동으로 커밋할지 수동으로 커밋할지 선택
        + auto.commit.interval.ms: 자동 커밋일 경우 오프셋 커밋 간격
        + max.poll.records: poll 메서드를 통해 반환되는 레코드 개수를 지정
        + session.timeout.ms: 컨슈머가 브로커와 연결이 끊기는 최대 시간. 이 시간 내에 하트비트가 전송되지 않으면 리밸런싱이 이뤄짐
        + hearbeat.interval.ms: 하트비트를 전송하는 시간 간격
        + max.poll.interval.ms: poll 메서드를 호출하는 간격의 최대 시간
        + isolation.level: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용

- 동기 오프셋 커밋
    * poll 메서드가 호출된 이후에 commitSync 메서드를 호출해서 오프셋 커밋을 명시적으로 수행
    * commitSync는 poll 메서드로 받은 가장 마지막 레코드의 오프셋 기준으로 커밋
    
- 비동기 오프셋 커밋
    * commitAsync 메서드를 호출해서 사용. 동기 오프셋 커밋과 동일하게 poll 메서드로 리턴된 가장 마지막 레코드를 기준으로 오프셋 커밋

- 리밸런스 리스너를 가진 컨슈머
    * 리밸런스 발생시 데이터를 중복 처리하지 않게 하기 위해서는 리밸런스 발생시 처리한 데이터를 기준으로 다시 커밋을 시도 해야함
    * 리밸런스 발생 감지를 위해 카프카 라이브러리는 ConsumerRebalanceLitener 인터페이스를 지원
    * ConsumerRebalanceLitener 의 구현제는 onPartitionAssigned 메서드와 onPartitionRevoked 메서드로 이뤄져 있는데, onPartitionAssigned는 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되고, onPartitionRevoked는 리밸런스 시작되기 직전에 호출
    * 마지막으로 처리한 레코드를 기준으로 커밋 하기 위해서는 리밸런스 시작 직전에 커밋을 하면 되므로 onPartitionRevoked에 커밋을 구현해서 처리 가능

- 파티션 할당 컨슈머
    * subscribe메서드를 사용해서 구독형태로 사용하는것 외에도 직접 파티션을 컨슈머에 명시적으로 할당하여 운영 할 수도 있음
    * 컨슈머가 어떤 토픽, 파티션을 할당할지 명시적으로 선언할때에는 assign메서드 사용

- 컨슈머에 할당된 파티션 확인 방법: assignment 메서드를 통해서 확인
- 컨슈머의 안전한 종료
    * 정상적으로 종료되지 않은 컨슈머는 세션타임아웃시까지 컨슈머 그룹에 남게 되므로 컨슈머 랙이 늘어나서 데이터 처리 지연이 발생할 수 있음
    * 컨슈머를 안전하게 종료하기 위해 KafkaConsumer 클래스는 wakeup메서드를 지원 하는데, wakeup메서드를 실행해서 KafkaConsumer 인스턴스를 안전하게 종료 가능
    * wakeup이후 poll이 호출되면 WakeupException이 발생 하는데, 이때 리소스를 종료처리 시키고 마지막으로 close메서드를 호출해서 클러스터에 컨슈머가 안전하게 종료되었음을 알려줌
    
### 어드민 API
- 카프카 클라이언트에서는 내부 옵션들을 설정하거나 조회하기 위해 AdminClient 클래스를 제공하는데, 이를 이용해 클러스터의 옵션과 관련된 부분을 자동화 할 수있음
- AdminClient 활용 예시: 카프카 컨슈머를 멀티스레드로 구성시 구독하는 토픽의 파티션 개수만큼 스레드 생성하고 싶을때, ACL이 적용된 클러스터의 리소스 접근 권한 규칙 관리, 브로커 정보 조회, 토픽 정보 조회

## 카프카 스트림즈
- 토픽에 적재된 데이터를 Stateful 또는 Stateless으로 실시간으로 변환 하여 다른 토픽에 적재하는 라이브러리
- 카프카 스트림즈 어플리케이션은 카프카 클러스터와 완벽히 호환되며, 스트림 처리에 필요한 편리한 기능들(신규 토픽 생성, 상태 저장, 데이터 조인)등을 제공
- 스트림즈 어플리케이션 또는 카프카 브로커의 장애가 발생 하더라도 exactly once 할 수 있도록 장애 허용 시스템을 가지고 있어서 데이터 안정성이 뛰어남
- 스트림즈 어플리케이션은 내부적으로 스레드를 1개 이상 생성 가능. 스레드는 1개 이상의 태스크(데이터 처리의 최소 단위)를 갖는데, 만약 3개의 파티션으로 이뤄진 토픽을 처리하는 스트림 어플리케이션을 실행 하면 내부에 3개의 태스크가 생김
- 카프카 스트림즈는 컨슈머 스레드를 늘리는 방법과 동일하게 병렬 처리를 위해 파티션과 스트림즈 스레드(또는 프로세스 개수를 늘림 으로써 처리량을 늘릴 수 있다)
- 토폴로지: 2개 이상의 노드들과 선으로 이뤄진 집합. 종류로는 Ring, Tree, Start등이 있는데 스트림즈에서는 Tree형태와 유사
- 카프카 스트림즈에서 토폴로지를 이루는 노드를 하나의 프로세서라 부르고, 노드와 노드를 이은 선을 스트림 이라고 부름(스트림은 토픽의 데이터를 뜻하는데, 프로듀서와 컨슈머 사이의 레코드와 동일)
- 프로세서에서는 소스 프로세서, 스트림 프로세서, 싱크 프로세서 3가지가 있음
    * 소스 프로세서: 데이터를 처리하기 위해 최초로 선언해야 하는 노드. 하나 이상의 토픽에서 데이터를 가져오는 역할
    * 스트림 프로세서: 다른 프로세서가 반환한 데이터를 처리하는 역할. 변환, 분기처리와 같은 로직이 데이터 처리의 일종
    * 싱크 프로세서: 데이터를 특정 카프카 토픽으로 저장하는 역할. 스트림즈로 처리된 데이터의 최종 목적지

- 스트림즈 DSL: 스트림 프로세싱에 쓰일 만한 다양한 기능들이 자체 API로 제공됨. 대부분의 변환 로직을 어렵지 않게 개발
    * 메시지 값을 기반으로 토픽 분기 처리
    * 지난 10분간 들어온 데이터의 개수 집계
    * 토픽과 다른 토픽의 결합으로 새로운 데이터 생성

- 프로세서 API
    * 메시지 값의 종류에 따라 토픽을 가변적으로 전송
    * 일정한 시간 간격으로 데이터 처리

### 스트림즈 DSL
- KStream: 레코드의 흐름을 표현한 것. 메시지 키와 값으로 구성. 컨슈머로 토픽을 구독하는것과 동일한 선상에서 사용 하는 것
- KTable: KStream과 다르게 메시지 키를 기준으로 묶어서 사용. 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용. 동일한 메시지 키가 있으면 데이터가 업데이트 된것
- GlobalKTable: KTable과 동일 하게 메시지 키를 기준으로 묶어서 사용. GlobalKTable로 선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용. 극 태스크마다 GlobalKTable로 정의된 모든 데이터를 저장하고 사용하기 떄문에 스트림즈 애플리케이션의 로컬 스토리지 사용량이 증가함
- 스트림즈 DSL 주요 옵션
    * 필수 옵션
        + bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 프로커의 호스트 이름:포트를 1개 이상 작성. 2개 이상 브로커 정보를 입력해 일부 브로커에 이슈가 발생하더라도 접속하는데 이슈가 없도록 해야함
        + application.id: 스트림즈 애플리케이션을 구분하기 위한 고유한 아이디를 설정. 다른 로직을 가진 스트림즈 애플리케이션은 서로 다른 application.id 값을 가져야 함

    * 선택 옵션
        + default.key.serde: 레코드의 메시지 키를 직렬화/역직렬화 하는 클래스를 지정. 기본값은 바이트 직렬화/역직렬화 클래스
        + default.value.serde: 레코드의 메시지 값을 직렬화/역직렬화 하는 클래스를 지정. 기본값은 바이트 직렬화/역직렬화 클래스
        + num.stream.threads: 스트림 프로세싱 실행시 실행될 스레드 갯수. 기본값은 1
        + state.dir: rocksDB 저장소(key-value 형태. 카프카 스트림즈가 상태 기반 데이터 처리를 할 떄 로컬 저장소로 사용)가 위치할 디렉토리를 지정. 기본값은 /tmp/kafka-streams

- 스트림즈 DSL - stream(), to()
    + 특정 토픽을 KStream 형태로 가져 오려면 스트림즈 DSL의 stream() 메서드를 사용
    + KStream의 데이터를 특정 토픽으로 저장 하려면 스트림즈 DSL의 to메서드를 사용

- 스트림즈 DSL - filter()
    + 메시지 키 또는 메시지 값을 필터링 하여 특정 조건에 맞는 데이터를 골라낼 때 
    + 필터링 스트림 프로세서

- 스트림즈 DSL - KTable과 KStream을 join() 
    * KTable과 KStream은 메시지 키를 기준으로 조인할 수 있음. 카프카는 실시간으로 들어오는 데이터들을 조인 가능
    * 사용자의 이벤트 데이터를 데이터베이스에 저장하지 않고도 조인하여 스트리밍 처리 할 수 있다는 당점. 이를 통해 이벤트 기반 스트리밍과 데이터 파이프라인을 구성 할 수 있음
    * KTable은 동일한 메시지 키가 들어올 겨웅 가장 마지막 레코드를 유효한 데이터로 보기 때문에, 가장 최근에 바뀐 데이터로 조인을 수행할것

- 스트림즈 DSL - GlobalKTable과 KStream을 join
    * 코파티셔닝 되있지 않는 데이터를 조인하기 위해선 리파티셔닝 이후 하거나, KTable로 사용하는 토픽을 GlobalKTable로 선언해서 사용하는 방법이 있음

### 프로세서 API
- 토폴로지를 기준으로 데이터를 처리한다는 관점에서 스트림즈 DSL과 동일한 역할. 스트림즈 DSL보다 추가적인 상세 로직을 구현 가능. KStream, KTable, GlobalKTable이 없음
